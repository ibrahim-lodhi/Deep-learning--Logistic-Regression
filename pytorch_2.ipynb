{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# We are going to classify images"
      ],
      "metadata": {
        "id": "ExKWFfDTTy8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_bMzZE-SXep"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download training dataset\n",
        "dataset = MNIST(root='data/', download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jej95pA0UCWZ",
        "outputId": "b24c83e3-ac5a-48e0-ae42-0889b2b99785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 37.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.07MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.33MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tTOqnDDIU3sE",
        "outputId": "8b91e67b-da62-416f-a472-1762349cd9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.MNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`MNIST &lt;http://yann.lecun.com/exdb/mnist/&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 20);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_TKSHEBVUG3",
        "outputId": "24de5254-0ced-4f2c-bc4a-1aff3830a584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSPhR-Y9Vasc",
        "outputId": "2edca798-d92c-42c7-8a28-381ab6da9b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WrVceiAgV7B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = dataset[0]\n",
        "\n",
        "plt.imshow(image, cmap = 'grey')\n",
        "\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "mHV54ZiPWE5o",
        "outputId": "52d36100-10ef-4198-d7af-6016c5edf814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = dataset[10]\n",
        "\n",
        "plt.imshow(image, cmap = 'grey')\n",
        "\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "VEYa0MntW06j",
        "outputId": "0c215680-8466-43e5-9e61-c7bd85dd310e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "q6o0OZGzW6Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be converting these images into tensors"
      ],
      "metadata": {
        "id": "UTJp546cXQ7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking train data from dataset\n",
        "\n",
        "dataset = MNIST(root = 'data/', train = True, transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "uTTZg0l5XQBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor, label = dataset[0]\n",
        "print(img_tensor.shape, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqq04nDZXrmR",
        "outputId": "31dfe0ac-6137-49ad-b610-167e4827a6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_tensor[:,10:15,10:15])\n",
        "print(torch.max(img_tensor),torch.min(img_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq5xoA9YX5M5",
        "outputId": "94897758-0514-41aa-b964-364acd64f528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
            "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
            "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
            "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
            "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the image by passing in the 28x28 matrix\n",
        "\n",
        "plt.imshow(img_tensor[0,10:15,10:15], cmap = 'grey');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Rn7-gBTNY6by",
        "outputId": "925a5490-bca0-4b40-91f6-9665f1ec7df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARu0lEQVR4nO3dX2iVh/3H8W/U5ehsEmo77ULiWtbR4SSOai2hsHY1q0iR9m4XhQYHwkYylNyM3Ex2MeLVaLeKk/3rLuZ0G6SFjtaJnYZBXWMkYDta6OhFhtOsFzuJgZ265PwufpDfXFt/OTHfPOfE1wuei3N40ufDKeTNOU8Sm6rVajUAYImtKnoAACuTwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKNct9wbm5ubh8+XK0tLREU1PTcl8egFtQrVZjeno62tvbY9Wqm79HWfbAXL58OTo7O5f7sgAsoYmJiejo6LjpOcsemJaWluW+ZMP64Q9/WPSEhtDb21v0hIawf//+oic0hN/85jdFT2gIC/levuyB+c+PxXxEdnPr1q0rekJDaG1tLXpCQ/jUpz5V9ARWkIV8/3aTH4AUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIsajAHDlyJO69995Yu3ZtPPzww/Hmm28u9S4AGlzNgTl58mQMDAzEoUOH4uLFi7Ft27bYvXt3TE5OZuwDoEHVHJgf/OAHsX///ti3b19s2bIlfvzjH8enP/3p+PnPf56xD4AGVVNgPvzwwxgbG4uenp7/+w+sWhU9PT3xxhtvLPk4ABrXmlpO/uCDD2J2djY2bdp0w/ObNm2Kd95552O/plKpRKVSmX88NTW1iJkANJr0nyIbGhqKtra2+aOzszP7kgDUgZoCc/fdd8fq1avj6tWrNzx/9erVuOeeez72awYHB6NcLs8fExMTi18LQMOoKTDNzc2xffv2OHPmzPxzc3NzcebMmeju7v7YrymVStHa2nrDAcDKV9M9mIiIgYGB6O3tjR07dsTOnTvjueeei5mZmdi3b1/GPgAaVM2B+frXvx7/+Mc/4rvf/W5cuXIlvvzlL8drr732kRv/ANzeag5MRER/f3/09/cv9RYAVhB/iwyAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKRYU+TFq9VqkZeve+VyuegJrCD79+8vekJD+PWvf130hLpWrVYX/L3bOxgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApKg5MCMjI7F3795ob2+PpqameOmllxJmAdDoag7MzMxMbNu2LY4cOZKxB4AVYk2tX7Bnz57Ys2dPxhYAVhD3YABIUfM7mFpVKpWoVCrzj6emprIvCUAdSH8HMzQ0FG1tbfNHZ2dn9iUBqAPpgRkcHIxyuTx/TExMZF8SgDqQ/hFZqVSKUqmUfRkA6kzNgbl27Vq8995784/ff//9GB8fjw0bNsTmzZuXdBwAjavmwFy4cCG++tWvzj8eGBiIiIje3t548cUXl2wYAI2t5sA89thjUa1WM7YAsIL4PRgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJCiqVqtVpfzglNTU9HW1racl2xY69evL3pCQ/j9739f9ISG8OijjxY9oSHs3r276Al17d///ne8/vrrUS6Xo7W19abnegcDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQ1BWZoaCgeeuihaGlpiY0bN8bTTz8d7777btY2ABpYTYE5d+5c9PX1xfnz5+P06dNx/fr1eOKJJ2JmZiZrHwANak0tJ7/22ms3PH7xxRdj48aNMTY2Fl/5yleWdBgAja2mwPy3crkcEREbNmz4xHMqlUpUKpX5x1NTU7dySQAaxKJv8s/NzcXBgwfjkUceia1bt37ieUNDQ9HW1jZ/dHZ2LvaSADSQRQemr68v3nrrrThx4sRNzxscHIxyuTx/TExMLPaSADSQRX1E1t/fH6+88kqMjIxER0fHTc8tlUpRKpUWNQ6AxlVTYKrVanz729+O4eHhOHv2bNx3331ZuwBocDUFpq+vL44fPx4vv/xytLS0xJUrVyIioq2tLdatW5cyEIDGVNM9mKNHj0a5XI7HHnssPvvZz84fJ0+ezNoHQIOq+SMyAFgIf4sMgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkaKpWq9XlvODU1FS0tbUt5yVZ4T7/+c8XPaEhjI+PFz2hIfzzn/8sekJdm56eji1btkS5XI7W1tabnusdDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABS1BSYo0ePRldXV7S2tkZra2t0d3fHq6++mrUNgAZWU2A6Ojri8OHDMTY2FhcuXIjHH388nnrqqXj77bez9gHQoNbUcvLevXtvePz9738/jh49GufPn48vfelLSzoMgMZWU2D+0+zsbPz2t7+NmZmZ6O7u/sTzKpVKVCqV+cdTU1OLvSQADaTmm/yXLl2KO+64I0qlUnzzm9+M4eHh2LJlyyeePzQ0FG1tbfNHZ2fnLQ0GoDHUHJgHHnggxsfH489//nN861vfit7e3vjLX/7yiecPDg5GuVyePyYmJm5pMACNoeaPyJqbm+P++++PiIjt27fH6OhoPP/883Hs2LGPPb9UKkWpVLq1lQA0nFv+PZi5ubkb7rEAQESN72AGBwdjz549sXnz5pieno7jx4/H2bNn49SpU1n7AGhQNQVmcnIynn322fj73/8ebW1t0dXVFadOnYqvfe1rWfsAaFA1BeZnP/tZ1g4AVhh/iwyAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKRYU/QAuFV//etfi57QEJ599tmiJzSEX/7yl0VPqGtNTU0LPtc7GABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkuKXAHD58OJqamuLgwYNLNAeAlWLRgRkdHY1jx45FV1fXUu4BYIVYVGCuXbsWzzzzTPzkJz+JO++8c6k3AbACLCowfX198eSTT0ZPT8//e26lUompqakbDgBWvjW1fsGJEyfi4sWLMTo6uqDzh4aG4nvf+17NwwBobDW9g5mYmIgDBw7Er371q1i7du2CvmZwcDDK5fL8MTExsaihADSWmt7BjI2NxeTkZDz44IPzz83OzsbIyEi88MILUalUYvXq1Td8TalUilKptDRrAWgYNQVm165dcenSpRue27dvX3zxi1+M73znOx+JCwC3r5oC09LSElu3br3hufXr18ddd931kecBuL35TX4AUtT8U2T/7ezZs0swA4CVxjsYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFmuW+YLVaXe5LAhFx/fr1oic0hKmpqaIn1LXp6emIWNj38qbqMn/H/9vf/hadnZ3LeUkAltjExER0dHTc9JxlD8zc3Fxcvnw5WlpaoqmpaTkv/Ymmpqais7MzJiYmorW1teg5dclrtDBep4XxOi1MPb5O1Wo1pqeno729PVatuvldlmX/iGzVqlX/b/WK0traWjf/E+uV12hhvE4L43VamHp7ndra2hZ0npv8AKQQGABSCExElEqlOHToUJRKpaKn1C2v0cJ4nRbG67Qwjf46LftNfgBuD97BAJBCYABIITAApBAYAFLc9oE5cuRI3HvvvbF27dp4+OGH48033yx6Ut0ZGRmJvXv3Rnt7ezQ1NcVLL71U9KS6MzQ0FA899FC0tLTExo0b4+mnn45333236Fl15+jRo9HV1TX/i4Pd3d3x6quvFj2r7h0+fDiampri4MGDRU+pyW0dmJMnT8bAwEAcOnQoLl68GNu2bYvdu3fH5ORk0dPqyszMTGzbti2OHDlS9JS6de7cuejr64vz58/H6dOn4/r16/HEE0/EzMxM0dPqSkdHRxw+fDjGxsbiwoUL8fjjj8dTTz0Vb7/9dtHT6tbo6GgcO3Ysurq6ip5Su+ptbOfOndW+vr75x7Ozs9X29vbq0NBQgavqW0RUh4eHi55R9yYnJ6sRUT137lzRU+renXfeWf3pT39a9Iy6ND09Xf3CF75QPX36dPXRRx+tHjhwoOhJNblt38F8+OGHMTY2Fj09PfPPrVq1Knp6euKNN94ocBkrQblcjoiIDRs2FLykfs3OzsaJEydiZmYmuru7i55Tl/r6+uLJJ5+84ftUI1n2P3ZZLz744IOYnZ2NTZs23fD8pk2b4p133iloFSvB3NxcHDx4MB555JHYunVr0XPqzqVLl6K7uzv+9a9/xR133BHDw8OxZcuWomfVnRMnTsTFixdjdHS06CmLdtsGBrL09fXFW2+9FX/605+KnlKXHnjggRgfH49yuRy/+93vore3N86dOycy/2FiYiIOHDgQp0+fjrVr1xY9Z9Fu28DcfffdsXr16rh69eoNz1+9ejXuueeeglbR6Pr7++OVV16JkZGRuv1nKYrW3Nwc999/f0REbN++PUZHR+P555+PY8eOFbysfoyNjcXk5GQ8+OCD88/Nzs7GyMhIvPDCC1GpVGL16tUFLlyY2/YeTHNzc2zfvj3OnDkz/9zc3FycOXPG58HUrFqtRn9/fwwPD8frr78e9913X9GTGsbc3FxUKpWiZ9SVXbt2xaVLl2J8fHz+2LFjRzzzzDMxPj7eEHGJuI3fwUREDAwMRG9vb+zYsSN27twZzz33XMzMzMS+ffuKnlZXrl27Fu+999784/fffz/Gx8djw4YNsXnz5gKX1Y++vr44fvx4vPzyy9HS0hJXrlyJiP/9h5nWrVtX8Lr6MTg4GHv27InNmzfH9PR0HD9+PM6ePRunTp0qelpdaWlp+cj9u/Xr18ddd93VWPf1iv4xtqL96Ec/qm7evLna3Nxc3blzZ/X8+fNFT6o7f/zjH6sR8ZGjt7e36Gl14+Nen4io/uIXvyh6Wl35xje+Uf3c5z5XbW5urn7mM5+p7tq1q/qHP/yh6FkNoRF/TNmf6wcgxW17DwaAXAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkOJ/ADBU38X4ClCmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will be divinding the data into test, train and validation."
      ],
      "metadata": {
        "id": "sfpc2xgFaxbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST dataset has 6000 train images and 10000 test images by default.\n",
        "We will be selecting some images for validation from train images."
      ],
      "metadata": {
        "id": "3VS5zjXWa7yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do this by random_split method from pytorch"
      ],
      "metadata": {
        "id": "FmAcl6nIbOnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
        "\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwP5lfGKZjUW",
        "outputId": "24dfc9e2-881a-4b79-9e7d-eae057b6df9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will load the images in dataloader as the number of images is very large"
      ],
      "metadata": {
        "id": "aLhJ_YtYebLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Fsp4jZIibYJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle = True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "metadata": {
        "id": "2ttBtDZiencu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "RcL__bB8YUSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will define our model\n",
        "\n",
        "our model is **Logistic Regression** it has the same formula pred = x @ w.t() + b\n",
        "\n",
        "Just like linear regression we can use nn.linear to create the model intead of defining weights manually\n",
        "\n",
        "We have training data in images (1 x 28 x 28 ) which needs to be flattened out into a vector size of 784 (28*28) before being passed into model.\n",
        "\n",
        "the output can be from 0 till 9. The predicted label for an image is simply the one with the highest probability."
      ],
      "metadata": {
        "id": "Dt93Rw2UYWOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "c_KZcVB6e96z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "#Logistic regression model\n",
        "\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "metadata": {
        "id": "8K1KB0bNZpTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is larger so we will have to look at the weights"
      ],
      "metadata": {
        "id": "_cvFw0pkaQDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOhjNlDlZ6bE",
        "outputId": "4efbb002-5abe-4d84-c59f-0dc39d8aa71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr4w4TReaaht",
        "outputId": "25339679-0a8f-45d6-f450-daf11664389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try to generate our output for our first batch"
      ],
      "metadata": {
        "id": "J5t1NV_narJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "  print(labels)\n",
        "  print(images.shape)\n",
        "  output = model(images)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "jTo3VX83ae7x",
        "outputId": "c16360f1-a8f7-4ede-df1c-5546f18b3f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 6, 7, 5, 9, 8, 8, 8, 6, 2, 4, 2, 0, 4, 4, 5, 0, 1, 8, 4, 0, 1, 7, 2,\n",
            "        2, 7, 3, 1, 5, 8, 0, 2, 9, 6, 2, 1, 0, 1, 4, 7, 6, 1, 0, 8, 8, 4, 0, 7,\n",
            "        4, 9, 1, 2, 4, 0, 8, 6, 2, 5, 1, 3, 5, 6, 2, 1, 8, 0, 5, 2, 8, 7, 9, 8,\n",
            "        0, 1, 8, 6, 8, 3, 7, 8, 3, 1, 3, 9, 3, 2, 0, 8, 8, 9, 4, 8, 7, 4, 4, 6,\n",
            "        5, 8, 4, 6, 9, 8, 0, 0, 3, 8, 1, 5, 4, 8, 6, 6, 4, 3, 4, 8, 1, 6, 3, 6,\n",
            "        6, 8, 3, 6, 2, 9, 2, 1])\n",
            "torch.Size([128, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ecd2248f7619>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the shapes are not equal so we can not multiply them.\n",
        "\n",
        "We will have to flatten the images.\n",
        "\n",
        "So there will be additional functionality involve and we can not use nn.linear anymore we will have to use nn.module now\n"
      ],
      "metadata": {
        "id": "LOHTQKQjbv1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "  def forward(self,xb):\n",
        "      xb = xb.reshape(-1, 784)\n",
        "      out = self.linear(xb)\n",
        "      return out\n",
        "\n",
        "model = MnistModel()"
      ],
      "metadata": {
        "id": "dJ7cohaBa4Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.linear.weight.shape, model.linear.bias.shape)\n",
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nilq8YSncVU4",
        "outputId": "a8f0d773-cfdf-462f-afb9-b5db05887390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 784]) torch.Size([10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0257,  0.0180,  0.0111,  ..., -0.0317,  0.0119, -0.0239],\n",
              "         [-0.0264, -0.0214, -0.0120,  ..., -0.0108,  0.0030,  0.0076],\n",
              "         [ 0.0148,  0.0109,  0.0033,  ..., -0.0244,  0.0100,  0.0067],\n",
              "         ...,\n",
              "         [-0.0335, -0.0261, -0.0111,  ..., -0.0287,  0.0221, -0.0304],\n",
              "         [-0.0185, -0.0352,  0.0146,  ...,  0.0296, -0.0096,  0.0286],\n",
              "         [-0.0062, -0.0064, -0.0325,  ...,  0.0079, -0.0174, -0.0252]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0243,  0.0123,  0.0288,  0.0020, -0.0115,  0.0246, -0.0055, -0.0141,\n",
              "          0.0156,  0.0209], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after changing the shape lets try to use the custom model again"
      ],
      "metadata": {
        "id": "02xdyqjmgXgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    output = model(images)\n",
        "    break\n",
        "\n",
        "\n",
        "print(\"Output shape:\" ,output.shape)\n",
        "print('Sample output:', output.shape[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x4FFn5vgM1e",
        "outputId": "9c20cf7e-6053-48c3-be0f-c727c22693f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([128, 10])\n",
            "Sample output: torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert output rows in probabiility. We can use softmax function."
      ],
      "metadata": {
        "id": "seKn0YggjUiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "M_L9dzqwhOY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying softmax function for each output row\n",
        "\n",
        "probs = F.softmax(output, dim = 1)\n",
        "\n",
        "#Look at sample porbability\n",
        "\n",
        "print('sample porbabilities:\\n', probs[:2])\n",
        "\n",
        "# Add the probabilities of an output row\n",
        "\n",
        "print('sum:', torch.sum(probs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuFslq7rj3Dn",
        "outputId": "ad2014b8-a36c-4e57-e3e9-b5c5baa72201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample porbabilities:\n",
            " tensor([[0.1021, 0.1181, 0.0635, 0.0682, 0.0932, 0.1111, 0.1286, 0.1004, 0.1185,\n",
            "         0.0963],\n",
            "        [0.0867, 0.0887, 0.0830, 0.1059, 0.0963, 0.0991, 0.1143, 0.1104, 0.0875,\n",
            "         0.1280]], grad_fn=<SliceBackward0>)\n",
            "sum: tensor(1.0000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will determine which index of the element has the highest probability. This is done using torch.max"
      ],
      "metadata": {
        "id": "6I9CLI6-ljsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_probs, preds = torch.max(probs, dim = 1)\n",
        "\n",
        "print(preds)\n",
        "print(max_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSqCYhFSkhDU",
        "outputId": "a4ee6a8a-56d8-40fc-a7c0-46ed19ac9618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 4, 2, 4, 1, 7, 7, 7, 1, 4, 6, 6, 6, 4, 4, 4, 2, 9, 7, 1, 7, 6, 6,\n",
            "        1, 6, 6, 6, 6, 7, 6, 7, 4, 1, 6, 6, 6, 4, 7, 1, 7, 7, 1, 1, 4, 2, 4, 1,\n",
            "        1, 6, 6, 7, 1, 6, 6, 5, 1, 9, 7, 1, 4, 6, 6, 1, 7, 4, 1, 1, 1, 6, 6, 7,\n",
            "        1, 1, 2, 1, 1, 4, 6, 4, 3, 7, 6, 6, 2, 6, 1, 7, 1, 6, 6, 6, 6, 4, 1, 2,\n",
            "        1, 6, 6, 4, 1, 6, 4, 6, 6, 7, 7, 5, 6, 6, 1, 1, 1, 7, 7, 1, 1, 6, 7, 6,\n",
            "        4, 7, 1, 1, 1, 6, 5, 1])\n",
            "tensor([0.1286, 0.1280, 0.1089, 0.1262, 0.1112, 0.1325, 0.1315, 0.1328, 0.1428,\n",
            "        0.1566, 0.1182, 0.1316, 0.1146, 0.1303, 0.1213, 0.1376, 0.1639, 0.1282,\n",
            "        0.1261, 0.1205, 0.1567, 0.1178, 0.1238, 0.1590, 0.1312, 0.1339, 0.1309,\n",
            "        0.1314, 0.1197, 0.1439, 0.1276, 0.1288, 0.1127, 0.1284, 0.1399, 0.1455,\n",
            "        0.1382, 0.1355, 0.1296, 0.1234, 0.1208, 0.1309, 0.1665, 0.1363, 0.1323,\n",
            "        0.1234, 0.1237, 0.1292, 0.1236, 0.1372, 0.1181, 0.1262, 0.1267, 0.1271,\n",
            "        0.1460, 0.1290, 0.1469, 0.1162, 0.1274, 0.1362, 0.1342, 0.1319, 0.1209,\n",
            "        0.1144, 0.1238, 0.1492, 0.1278, 0.1291, 0.1350, 0.1420, 0.1245, 0.1364,\n",
            "        0.1351, 0.1170, 0.1200, 0.1221, 0.1311, 0.1325, 0.1220, 0.1436, 0.1135,\n",
            "        0.1174, 0.1381, 0.1144, 0.1316, 0.1537, 0.1423, 0.1316, 0.1339, 0.1208,\n",
            "        0.1224, 0.1237, 0.1328, 0.1213, 0.1136, 0.1345, 0.1161, 0.1250, 0.1251,\n",
            "        0.1370, 0.1221, 0.1619, 0.1451, 0.1313, 0.1375, 0.1237, 0.1370, 0.1481,\n",
            "        0.1400, 0.1291, 0.1369, 0.1587, 0.1355, 0.1285, 0.1308, 0.1383, 0.1187,\n",
            "        0.1511, 0.1349, 0.1166, 0.1154, 0.1374, 0.1632, 0.1150, 0.1307, 0.1486,\n",
            "        0.1250, 0.1365], grad_fn=<MaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwHD1l3rl8qJ",
        "outputId": "7f6dd9e2-91ec-4682-abac-808fd0440716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 3, 8, 8, 9, 4, 1, 5, 9, 0, 4, 6, 9, 6, 3, 7, 6, 9, 3, 1, 3, 5, 9,\n",
              "        1, 5, 0, 3, 0, 4, 7, 5, 5, 0, 0, 4, 1, 8, 1, 0, 9, 4, 0, 1, 7, 1, 1, 2,\n",
              "        6, 6, 3, 3, 1, 1, 7, 9, 2, 8, 1, 1, 1, 2, 5, 0, 6, 9, 2, 0, 1, 6, 8, 1,\n",
              "        4, 3, 5, 2, 0, 4, 0, 6, 4, 1, 0, 9, 5, 7, 8, 5, 4, 5, 9, 3, 9, 4, 1, 5,\n",
              "        7, 7, 7, 8, 8, 8, 7, 1, 6, 9, 3, 9, 8, 6, 0, 1, 9, 8, 6, 8, 9, 1, 9, 0,\n",
              "        0, 7, 6, 5, 0, 5, 0, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted values and actual labels are different. We will have to adjust weight and bias"
      ],
      "metadata": {
        "id": "M7QE6GnamZ1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets check the accuracy\n"
      ],
      "metadata": {
        "id": "QnMciFi2nVzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "    _, preds = (torch.max(preds, dim = 1))\n",
        "    return torch.tensor(torch.sum(preds == labels).item()/len(preds))"
      ],
      "metadata": {
        "id": "kKzbZFuGmBMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(output,labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87SZRbRDn0-e",
        "outputId": "2bfe9f84-be9a-41cd-da6d-c27294d069ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0625)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy"
      ],
      "metadata": {
        "id": "I9xoBTSe2fLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = F.cross_entropy"
      ],
      "metadata": {
        "id": "sLbYWo2qoFK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss for current batch of data\n",
        "\n",
        "Loss = loss_fn(output,labels)\n",
        "print(Loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA5fS2Nh3KSx",
        "outputId": "46d8f5b5-f4dc-4738-92ce-65a4847bf484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3042, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "Now that we have defined the data loaders,model,loss function and optimizer, we are ready to train the model. The training phase is identical to linear regression with the addtition of a validation phase to evaluate the model in each epoch.\n",
        "\n",
        "Here is the pseudocode for the step:"
      ],
      "metadata": {
        "id": "minmxpO_BGnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for epoch in range(num_epochs):\n",
        "  #Training phase\n",
        "#  for batch in train_loader:\n",
        "    #Generate predictions.\n",
        "    #Calculate loss.\n",
        "    #Compute gradient.\n",
        "    #Update weights.\n",
        "    #Reset Gradients.\n",
        "\n",
        "  #Validation phase\n",
        "#  for batch in val_loader:\n",
        "    #Generate predictions.\n",
        "    #Calculate loss.\n",
        "    #Calculate matrics(accuracy etc)\n",
        "\n",
        "  #Calculate average validation loss and matrices\n",
        "\n",
        "  #log epoch, loss & matrics for inspection\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QHb7HErM3dqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this loop we have some steps that are generic and some are problem specific. Steps which are problem specific we will add the with our Mnist class"
      ],
      "metadata": {
        "id": "vMcExqvmDelt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):       #predefined\n",
        "    super().__init__()      #predefined\n",
        "    self.linear = nn.Linear(input_size, num_classes)   #nnlinear is provided with arguments of input size and num classes.\n",
        "\n",
        "  def forward(self,xb):\n",
        "      xb = xb.reshape(-1, 784)  # Training steps are given two arguments to run thorugh and xb is given to be reshaped into vector so that it can be used\n",
        "      out = self.linear(xb)\n",
        "      return out\n",
        "\n",
        "  def training_step(self,batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                #Generate predictions\n",
        "        loss = F.cross_entropy(out,labels)    # Calculate loss\n",
        "        return loss\n",
        "\n",
        "  def validation_step(self,batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                #Generate predictions\n",
        "        loss = F.cross_entropy(out,labels)    # Calculate loss\n",
        "        acc = accuracy(out,labels)          # Calculate accuracy\n",
        "        return{'val_loss': loss, 'val_acc' : acc}\n",
        "\n",
        "\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   #Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      #Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "\n",
        "  def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "\n",
        "model = MnistModel()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4cudN0Q7DPde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation and Fit the model\n",
        "\n",
        "Now we will define an evaluate function, which will perform the validation phase and a fit function which will perform the entire training process\n"
      ],
      "metadata": {
        "id": "LQIZkIfJmRhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "  output = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(output)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(), lr)\n",
        "  for epoch in range(epochs):\n",
        "    #Training phase\n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #Validation phase\n",
        "      result = evaluate(model, val_loader)\n",
        "      model.epoch_end(epoch, result)\n",
        "      history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "DmHXgeZjEvwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result0 = evaluate(model, val_loader)"
      ],
      "metadata": {
        "id": "zuC7HRC-qK2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKXUKg-Trl6U",
        "outputId": "6b3a1c50-8893-4ddf-99a4-5e5d6e6ad79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 2.330566883087158, 'val_acc': 0.08771756291389465}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = fit(5, 0.001, model, train_loader, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BrejyVht3Bj",
        "outputId": "91d015c3-cd79-4878-98ef-dd3c88758611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 2.3295, val_acc: 0.0881\n",
            "Epoch [0], val_loss: 2.3283, val_acc: 0.0883\n",
            "Epoch [0], val_loss: 2.3270, val_acc: 0.0890\n",
            "Epoch [0], val_loss: 2.3258, val_acc: 0.0896\n",
            "Epoch [0], val_loss: 2.3248, val_acc: 0.0899\n",
            "Epoch [0], val_loss: 2.3235, val_acc: 0.0900\n",
            "Epoch [0], val_loss: 2.3226, val_acc: 0.0903\n",
            "Epoch [0], val_loss: 2.3215, val_acc: 0.0907\n",
            "Epoch [0], val_loss: 2.3204, val_acc: 0.0914\n",
            "Epoch [0], val_loss: 2.3192, val_acc: 0.0918\n",
            "Epoch [0], val_loss: 2.3180, val_acc: 0.0922\n",
            "Epoch [0], val_loss: 2.3169, val_acc: 0.0926\n",
            "Epoch [0], val_loss: 2.3158, val_acc: 0.0941\n",
            "Epoch [0], val_loss: 2.3147, val_acc: 0.0949\n",
            "Epoch [0], val_loss: 2.3134, val_acc: 0.0954\n",
            "Epoch [0], val_loss: 2.3123, val_acc: 0.0962\n",
            "Epoch [0], val_loss: 2.3112, val_acc: 0.0969\n",
            "Epoch [0], val_loss: 2.3101, val_acc: 0.0974\n",
            "Epoch [0], val_loss: 2.3091, val_acc: 0.0979\n",
            "Epoch [0], val_loss: 2.3079, val_acc: 0.0985\n",
            "Epoch [0], val_loss: 2.3068, val_acc: 0.0999\n",
            "Epoch [0], val_loss: 2.3056, val_acc: 0.1008\n",
            "Epoch [0], val_loss: 2.3046, val_acc: 0.1014\n",
            "Epoch [0], val_loss: 2.3036, val_acc: 0.1020\n",
            "Epoch [0], val_loss: 2.3024, val_acc: 0.1024\n",
            "Epoch [0], val_loss: 2.3014, val_acc: 0.1031\n",
            "Epoch [0], val_loss: 2.3002, val_acc: 0.1042\n",
            "Epoch [0], val_loss: 2.2992, val_acc: 0.1045\n",
            "Epoch [0], val_loss: 2.2979, val_acc: 0.1063\n",
            "Epoch [0], val_loss: 2.2968, val_acc: 0.1068\n",
            "Epoch [0], val_loss: 2.2957, val_acc: 0.1067\n",
            "Epoch [0], val_loss: 2.2946, val_acc: 0.1073\n",
            "Epoch [0], val_loss: 2.2935, val_acc: 0.1075\n",
            "Epoch [0], val_loss: 2.2924, val_acc: 0.1081\n",
            "Epoch [0], val_loss: 2.2915, val_acc: 0.1085\n",
            "Epoch [0], val_loss: 2.2903, val_acc: 0.1092\n",
            "Epoch [0], val_loss: 2.2894, val_acc: 0.1097\n",
            "Epoch [0], val_loss: 2.2884, val_acc: 0.1106\n",
            "Epoch [0], val_loss: 2.2872, val_acc: 0.1123\n",
            "Epoch [0], val_loss: 2.2860, val_acc: 0.1125\n",
            "Epoch [0], val_loss: 2.2849, val_acc: 0.1134\n",
            "Epoch [0], val_loss: 2.2839, val_acc: 0.1137\n",
            "Epoch [0], val_loss: 2.2828, val_acc: 0.1149\n",
            "Epoch [0], val_loss: 2.2817, val_acc: 0.1153\n",
            "Epoch [0], val_loss: 2.2806, val_acc: 0.1164\n",
            "Epoch [0], val_loss: 2.2794, val_acc: 0.1170\n",
            "Epoch [0], val_loss: 2.2784, val_acc: 0.1182\n",
            "Epoch [0], val_loss: 2.2773, val_acc: 0.1188\n",
            "Epoch [0], val_loss: 2.2762, val_acc: 0.1196\n",
            "Epoch [0], val_loss: 2.2751, val_acc: 0.1206\n",
            "Epoch [0], val_loss: 2.2740, val_acc: 0.1220\n",
            "Epoch [0], val_loss: 2.2729, val_acc: 0.1231\n",
            "Epoch [0], val_loss: 2.2718, val_acc: 0.1244\n",
            "Epoch [0], val_loss: 2.2707, val_acc: 0.1247\n",
            "Epoch [0], val_loss: 2.2695, val_acc: 0.1270\n",
            "Epoch [0], val_loss: 2.2684, val_acc: 0.1280\n",
            "Epoch [0], val_loss: 2.2673, val_acc: 0.1298\n",
            "Epoch [0], val_loss: 2.2663, val_acc: 0.1307\n",
            "Epoch [0], val_loss: 2.2652, val_acc: 0.1317\n",
            "Epoch [0], val_loss: 2.2641, val_acc: 0.1331\n",
            "Epoch [0], val_loss: 2.2631, val_acc: 0.1344\n",
            "Epoch [0], val_loss: 2.2620, val_acc: 0.1356\n",
            "Epoch [0], val_loss: 2.2608, val_acc: 0.1368\n",
            "Epoch [0], val_loss: 2.2596, val_acc: 0.1392\n",
            "Epoch [0], val_loss: 2.2586, val_acc: 0.1408\n",
            "Epoch [0], val_loss: 2.2575, val_acc: 0.1426\n",
            "Epoch [0], val_loss: 2.2563, val_acc: 0.1445\n",
            "Epoch [0], val_loss: 2.2553, val_acc: 0.1461\n",
            "Epoch [0], val_loss: 2.2540, val_acc: 0.1475\n",
            "Epoch [0], val_loss: 2.2530, val_acc: 0.1496\n",
            "Epoch [0], val_loss: 2.2518, val_acc: 0.1508\n",
            "Epoch [0], val_loss: 2.2506, val_acc: 0.1534\n",
            "Epoch [0], val_loss: 2.2495, val_acc: 0.1562\n",
            "Epoch [0], val_loss: 2.2485, val_acc: 0.1568\n",
            "Epoch [0], val_loss: 2.2473, val_acc: 0.1594\n",
            "Epoch [0], val_loss: 2.2462, val_acc: 0.1611\n",
            "Epoch [0], val_loss: 2.2450, val_acc: 0.1635\n",
            "Epoch [0], val_loss: 2.2440, val_acc: 0.1660\n",
            "Epoch [0], val_loss: 2.2429, val_acc: 0.1683\n",
            "Epoch [0], val_loss: 2.2418, val_acc: 0.1706\n",
            "Epoch [0], val_loss: 2.2407, val_acc: 0.1723\n",
            "Epoch [0], val_loss: 2.2398, val_acc: 0.1740\n",
            "Epoch [0], val_loss: 2.2387, val_acc: 0.1744\n",
            "Epoch [0], val_loss: 2.2376, val_acc: 0.1766\n",
            "Epoch [0], val_loss: 2.2366, val_acc: 0.1777\n",
            "Epoch [0], val_loss: 2.2354, val_acc: 0.1804\n",
            "Epoch [0], val_loss: 2.2344, val_acc: 0.1818\n",
            "Epoch [0], val_loss: 2.2333, val_acc: 0.1841\n",
            "Epoch [0], val_loss: 2.2323, val_acc: 0.1855\n",
            "Epoch [0], val_loss: 2.2312, val_acc: 0.1872\n",
            "Epoch [0], val_loss: 2.2301, val_acc: 0.1895\n",
            "Epoch [0], val_loss: 2.2290, val_acc: 0.1917\n",
            "Epoch [0], val_loss: 2.2280, val_acc: 0.1946\n",
            "Epoch [0], val_loss: 2.2269, val_acc: 0.1967\n",
            "Epoch [0], val_loss: 2.2259, val_acc: 0.1988\n",
            "Epoch [0], val_loss: 2.2248, val_acc: 0.2006\n",
            "Epoch [0], val_loss: 2.2239, val_acc: 0.2026\n",
            "Epoch [0], val_loss: 2.2228, val_acc: 0.2037\n",
            "Epoch [0], val_loss: 2.2216, val_acc: 0.2074\n",
            "Epoch [0], val_loss: 2.2205, val_acc: 0.2105\n",
            "Epoch [0], val_loss: 2.2195, val_acc: 0.2124\n",
            "Epoch [0], val_loss: 2.2184, val_acc: 0.2154\n",
            "Epoch [0], val_loss: 2.2174, val_acc: 0.2169\n",
            "Epoch [0], val_loss: 2.2165, val_acc: 0.2189\n",
            "Epoch [0], val_loss: 2.2153, val_acc: 0.2219\n",
            "Epoch [0], val_loss: 2.2142, val_acc: 0.2240\n",
            "Epoch [0], val_loss: 2.2132, val_acc: 0.2263\n",
            "Epoch [0], val_loss: 2.2122, val_acc: 0.2284\n",
            "Epoch [0], val_loss: 2.2111, val_acc: 0.2311\n",
            "Epoch [0], val_loss: 2.2100, val_acc: 0.2340\n",
            "Epoch [0], val_loss: 2.2090, val_acc: 0.2359\n",
            "Epoch [0], val_loss: 2.2081, val_acc: 0.2387\n",
            "Epoch [0], val_loss: 2.2070, val_acc: 0.2404\n",
            "Epoch [0], val_loss: 2.2059, val_acc: 0.2427\n",
            "Epoch [0], val_loss: 2.2049, val_acc: 0.2449\n",
            "Epoch [0], val_loss: 2.2040, val_acc: 0.2472\n",
            "Epoch [0], val_loss: 2.2030, val_acc: 0.2480\n",
            "Epoch [0], val_loss: 2.2020, val_acc: 0.2493\n",
            "Epoch [0], val_loss: 2.2010, val_acc: 0.2519\n",
            "Epoch [0], val_loss: 2.2000, val_acc: 0.2535\n",
            "Epoch [0], val_loss: 2.1990, val_acc: 0.2553\n",
            "Epoch [0], val_loss: 2.1981, val_acc: 0.2573\n",
            "Epoch [0], val_loss: 2.1970, val_acc: 0.2586\n",
            "Epoch [0], val_loss: 2.1961, val_acc: 0.2606\n",
            "Epoch [0], val_loss: 2.1951, val_acc: 0.2631\n",
            "Epoch [0], val_loss: 2.1940, val_acc: 0.2653\n",
            "Epoch [0], val_loss: 2.1932, val_acc: 0.2664\n",
            "Epoch [0], val_loss: 2.1922, val_acc: 0.2676\n",
            "Epoch [0], val_loss: 2.1912, val_acc: 0.2693\n",
            "Epoch [0], val_loss: 2.1902, val_acc: 0.2712\n",
            "Epoch [0], val_loss: 2.1892, val_acc: 0.2726\n",
            "Epoch [0], val_loss: 2.1881, val_acc: 0.2756\n",
            "Epoch [0], val_loss: 2.1871, val_acc: 0.2777\n",
            "Epoch [0], val_loss: 2.1861, val_acc: 0.2798\n",
            "Epoch [0], val_loss: 2.1851, val_acc: 0.2816\n",
            "Epoch [0], val_loss: 2.1841, val_acc: 0.2834\n",
            "Epoch [0], val_loss: 2.1831, val_acc: 0.2847\n",
            "Epoch [0], val_loss: 2.1821, val_acc: 0.2877\n",
            "Epoch [0], val_loss: 2.1810, val_acc: 0.2889\n",
            "Epoch [0], val_loss: 2.1800, val_acc: 0.2893\n",
            "Epoch [0], val_loss: 2.1790, val_acc: 0.2923\n",
            "Epoch [0], val_loss: 2.1778, val_acc: 0.2945\n",
            "Epoch [0], val_loss: 2.1767, val_acc: 0.2964\n",
            "Epoch [0], val_loss: 2.1758, val_acc: 0.3009\n",
            "Epoch [0], val_loss: 2.1749, val_acc: 0.3031\n",
            "Epoch [0], val_loss: 2.1738, val_acc: 0.3045\n",
            "Epoch [0], val_loss: 2.1728, val_acc: 0.3058\n",
            "Epoch [0], val_loss: 2.1719, val_acc: 0.3075\n",
            "Epoch [0], val_loss: 2.1708, val_acc: 0.3098\n",
            "Epoch [0], val_loss: 2.1699, val_acc: 0.3131\n",
            "Epoch [0], val_loss: 2.1689, val_acc: 0.3153\n",
            "Epoch [0], val_loss: 2.1679, val_acc: 0.3173\n",
            "Epoch [0], val_loss: 2.1669, val_acc: 0.3190\n",
            "Epoch [0], val_loss: 2.1660, val_acc: 0.3204\n",
            "Epoch [0], val_loss: 2.1650, val_acc: 0.3237\n",
            "Epoch [0], val_loss: 2.1639, val_acc: 0.3250\n",
            "Epoch [0], val_loss: 2.1629, val_acc: 0.3263\n",
            "Epoch [0], val_loss: 2.1619, val_acc: 0.3290\n",
            "Epoch [0], val_loss: 2.1609, val_acc: 0.3304\n",
            "Epoch [0], val_loss: 2.1600, val_acc: 0.3331\n",
            "Epoch [0], val_loss: 2.1589, val_acc: 0.3365\n",
            "Epoch [0], val_loss: 2.1579, val_acc: 0.3383\n",
            "Epoch [0], val_loss: 2.1571, val_acc: 0.3402\n",
            "Epoch [0], val_loss: 2.1561, val_acc: 0.3433\n",
            "Epoch [0], val_loss: 2.1550, val_acc: 0.3459\n",
            "Epoch [0], val_loss: 2.1540, val_acc: 0.3485\n",
            "Epoch [0], val_loss: 2.1532, val_acc: 0.3498\n",
            "Epoch [0], val_loss: 2.1523, val_acc: 0.3519\n",
            "Epoch [0], val_loss: 2.1512, val_acc: 0.3537\n",
            "Epoch [0], val_loss: 2.1504, val_acc: 0.3560\n",
            "Epoch [0], val_loss: 2.1492, val_acc: 0.3582\n",
            "Epoch [0], val_loss: 2.1483, val_acc: 0.3596\n",
            "Epoch [0], val_loss: 2.1473, val_acc: 0.3620\n",
            "Epoch [0], val_loss: 2.1464, val_acc: 0.3644\n",
            "Epoch [0], val_loss: 2.1454, val_acc: 0.3662\n",
            "Epoch [0], val_loss: 2.1446, val_acc: 0.3678\n",
            "Epoch [0], val_loss: 2.1436, val_acc: 0.3699\n",
            "Epoch [0], val_loss: 2.1426, val_acc: 0.3715\n",
            "Epoch [0], val_loss: 2.1416, val_acc: 0.3732\n",
            "Epoch [0], val_loss: 2.1407, val_acc: 0.3752\n",
            "Epoch [0], val_loss: 2.1397, val_acc: 0.3780\n",
            "Epoch [0], val_loss: 2.1388, val_acc: 0.3802\n",
            "Epoch [0], val_loss: 2.1378, val_acc: 0.3827\n",
            "Epoch [0], val_loss: 2.1369, val_acc: 0.3832\n",
            "Epoch [0], val_loss: 2.1358, val_acc: 0.3866\n",
            "Epoch [0], val_loss: 2.1348, val_acc: 0.3880\n",
            "Epoch [0], val_loss: 2.1339, val_acc: 0.3896\n",
            "Epoch [0], val_loss: 2.1329, val_acc: 0.3919\n",
            "Epoch [0], val_loss: 2.1321, val_acc: 0.3945\n",
            "Epoch [0], val_loss: 2.1311, val_acc: 0.3958\n",
            "Epoch [0], val_loss: 2.1302, val_acc: 0.3979\n",
            "Epoch [0], val_loss: 2.1293, val_acc: 0.3999\n",
            "Epoch [0], val_loss: 2.1283, val_acc: 0.4014\n",
            "Epoch [0], val_loss: 2.1273, val_acc: 0.4049\n",
            "Epoch [0], val_loss: 2.1264, val_acc: 0.4074\n",
            "Epoch [0], val_loss: 2.1254, val_acc: 0.4099\n",
            "Epoch [0], val_loss: 2.1244, val_acc: 0.4115\n",
            "Epoch [0], val_loss: 2.1235, val_acc: 0.4136\n",
            "Epoch [0], val_loss: 2.1227, val_acc: 0.4171\n",
            "Epoch [0], val_loss: 2.1218, val_acc: 0.4193\n",
            "Epoch [0], val_loss: 2.1209, val_acc: 0.4212\n",
            "Epoch [0], val_loss: 2.1201, val_acc: 0.4225\n",
            "Epoch [0], val_loss: 2.1191, val_acc: 0.4237\n",
            "Epoch [0], val_loss: 2.1182, val_acc: 0.4262\n",
            "Epoch [0], val_loss: 2.1174, val_acc: 0.4281\n",
            "Epoch [0], val_loss: 2.1164, val_acc: 0.4301\n",
            "Epoch [0], val_loss: 2.1155, val_acc: 0.4316\n",
            "Epoch [0], val_loss: 2.1146, val_acc: 0.4335\n",
            "Epoch [0], val_loss: 2.1136, val_acc: 0.4363\n",
            "Epoch [0], val_loss: 2.1126, val_acc: 0.4379\n",
            "Epoch [0], val_loss: 2.1116, val_acc: 0.4396\n",
            "Epoch [0], val_loss: 2.1107, val_acc: 0.4414\n",
            "Epoch [0], val_loss: 2.1097, val_acc: 0.4431\n",
            "Epoch [0], val_loss: 2.1088, val_acc: 0.4446\n",
            "Epoch [0], val_loss: 2.1079, val_acc: 0.4471\n",
            "Epoch [0], val_loss: 2.1070, val_acc: 0.4493\n",
            "Epoch [0], val_loss: 2.1061, val_acc: 0.4511\n",
            "Epoch [0], val_loss: 2.1051, val_acc: 0.4527\n",
            "Epoch [0], val_loss: 2.1042, val_acc: 0.4542\n",
            "Epoch [0], val_loss: 2.1033, val_acc: 0.4556\n",
            "Epoch [0], val_loss: 2.1024, val_acc: 0.4572\n",
            "Epoch [0], val_loss: 2.1014, val_acc: 0.4585\n",
            "Epoch [0], val_loss: 2.1004, val_acc: 0.4597\n",
            "Epoch [0], val_loss: 2.0995, val_acc: 0.4614\n",
            "Epoch [0], val_loss: 2.0986, val_acc: 0.4637\n",
            "Epoch [0], val_loss: 2.0978, val_acc: 0.4656\n",
            "Epoch [0], val_loss: 2.0968, val_acc: 0.4685\n",
            "Epoch [0], val_loss: 2.0958, val_acc: 0.4705\n",
            "Epoch [0], val_loss: 2.0950, val_acc: 0.4721\n",
            "Epoch [0], val_loss: 2.0941, val_acc: 0.4731\n",
            "Epoch [0], val_loss: 2.0931, val_acc: 0.4748\n",
            "Epoch [0], val_loss: 2.0922, val_acc: 0.4766\n",
            "Epoch [0], val_loss: 2.0913, val_acc: 0.4788\n",
            "Epoch [0], val_loss: 2.0905, val_acc: 0.4799\n",
            "Epoch [0], val_loss: 2.0896, val_acc: 0.4813\n",
            "Epoch [0], val_loss: 2.0887, val_acc: 0.4817\n",
            "Epoch [0], val_loss: 2.0877, val_acc: 0.4837\n",
            "Epoch [0], val_loss: 2.0869, val_acc: 0.4858\n",
            "Epoch [0], val_loss: 2.0860, val_acc: 0.4870\n",
            "Epoch [0], val_loss: 2.0850, val_acc: 0.4882\n",
            "Epoch [0], val_loss: 2.0841, val_acc: 0.4898\n",
            "Epoch [0], val_loss: 2.0832, val_acc: 0.4919\n",
            "Epoch [0], val_loss: 2.0822, val_acc: 0.4931\n",
            "Epoch [0], val_loss: 2.0813, val_acc: 0.4936\n",
            "Epoch [0], val_loss: 2.0804, val_acc: 0.4955\n",
            "Epoch [0], val_loss: 2.0795, val_acc: 0.4961\n",
            "Epoch [0], val_loss: 2.0787, val_acc: 0.4966\n",
            "Epoch [0], val_loss: 2.0778, val_acc: 0.4980\n",
            "Epoch [0], val_loss: 2.0769, val_acc: 0.5002\n",
            "Epoch [0], val_loss: 2.0759, val_acc: 0.5014\n",
            "Epoch [0], val_loss: 2.0750, val_acc: 0.5026\n",
            "Epoch [0], val_loss: 2.0740, val_acc: 0.5033\n",
            "Epoch [0], val_loss: 2.0731, val_acc: 0.5045\n",
            "Epoch [0], val_loss: 2.0722, val_acc: 0.5075\n",
            "Epoch [0], val_loss: 2.0712, val_acc: 0.5098\n",
            "Epoch [0], val_loss: 2.0702, val_acc: 0.5129\n",
            "Epoch [0], val_loss: 2.0694, val_acc: 0.5138\n",
            "Epoch [0], val_loss: 2.0685, val_acc: 0.5140\n",
            "Epoch [0], val_loss: 2.0675, val_acc: 0.5141\n",
            "Epoch [0], val_loss: 2.0666, val_acc: 0.5170\n",
            "Epoch [0], val_loss: 2.0656, val_acc: 0.5191\n",
            "Epoch [0], val_loss: 2.0647, val_acc: 0.5197\n",
            "Epoch [0], val_loss: 2.0638, val_acc: 0.5216\n",
            "Epoch [0], val_loss: 2.0629, val_acc: 0.5225\n",
            "Epoch [0], val_loss: 2.0619, val_acc: 0.5243\n",
            "Epoch [0], val_loss: 2.0611, val_acc: 0.5260\n",
            "Epoch [0], val_loss: 2.0602, val_acc: 0.5276\n",
            "Epoch [0], val_loss: 2.0592, val_acc: 0.5286\n",
            "Epoch [0], val_loss: 2.0584, val_acc: 0.5298\n",
            "Epoch [0], val_loss: 2.0575, val_acc: 0.5308\n",
            "Epoch [0], val_loss: 2.0566, val_acc: 0.5327\n",
            "Epoch [0], val_loss: 2.0556, val_acc: 0.5332\n",
            "Epoch [0], val_loss: 2.0547, val_acc: 0.5352\n",
            "Epoch [0], val_loss: 2.0538, val_acc: 0.5372\n",
            "Epoch [0], val_loss: 2.0528, val_acc: 0.5367\n",
            "Epoch [0], val_loss: 2.0520, val_acc: 0.5381\n",
            "Epoch [0], val_loss: 2.0510, val_acc: 0.5386\n",
            "Epoch [0], val_loss: 2.0501, val_acc: 0.5409\n",
            "Epoch [0], val_loss: 2.0492, val_acc: 0.5415\n",
            "Epoch [0], val_loss: 2.0482, val_acc: 0.5421\n",
            "Epoch [0], val_loss: 2.0474, val_acc: 0.5433\n",
            "Epoch [0], val_loss: 2.0466, val_acc: 0.5455\n",
            "Epoch [0], val_loss: 2.0457, val_acc: 0.5462\n",
            "Epoch [0], val_loss: 2.0448, val_acc: 0.5488\n",
            "Epoch [0], val_loss: 2.0439, val_acc: 0.5501\n",
            "Epoch [0], val_loss: 2.0431, val_acc: 0.5502\n",
            "Epoch [0], val_loss: 2.0422, val_acc: 0.5510\n",
            "Epoch [0], val_loss: 2.0413, val_acc: 0.5527\n",
            "Epoch [0], val_loss: 2.0404, val_acc: 0.5536\n",
            "Epoch [0], val_loss: 2.0395, val_acc: 0.5559\n",
            "Epoch [0], val_loss: 2.0386, val_acc: 0.5553\n",
            "Epoch [0], val_loss: 2.0376, val_acc: 0.5560\n",
            "Epoch [0], val_loss: 2.0368, val_acc: 0.5574\n",
            "Epoch [0], val_loss: 2.0360, val_acc: 0.5574\n",
            "Epoch [0], val_loss: 2.0351, val_acc: 0.5591\n",
            "Epoch [0], val_loss: 2.0341, val_acc: 0.5601\n",
            "Epoch [0], val_loss: 2.0333, val_acc: 0.5609\n",
            "Epoch [0], val_loss: 2.0325, val_acc: 0.5624\n",
            "Epoch [0], val_loss: 2.0316, val_acc: 0.5639\n",
            "Epoch [0], val_loss: 2.0307, val_acc: 0.5642\n",
            "Epoch [0], val_loss: 2.0298, val_acc: 0.5662\n",
            "Epoch [0], val_loss: 2.0289, val_acc: 0.5678\n",
            "Epoch [0], val_loss: 2.0281, val_acc: 0.5693\n",
            "Epoch [0], val_loss: 2.0272, val_acc: 0.5703\n",
            "Epoch [0], val_loss: 2.0263, val_acc: 0.5708\n",
            "Epoch [0], val_loss: 2.0254, val_acc: 0.5718\n",
            "Epoch [0], val_loss: 2.0245, val_acc: 0.5719\n",
            "Epoch [0], val_loss: 2.0235, val_acc: 0.5719\n",
            "Epoch [0], val_loss: 2.0226, val_acc: 0.5730\n",
            "Epoch [0], val_loss: 2.0218, val_acc: 0.5746\n",
            "Epoch [0], val_loss: 2.0210, val_acc: 0.5759\n",
            "Epoch [0], val_loss: 2.0201, val_acc: 0.5770\n",
            "Epoch [0], val_loss: 2.0192, val_acc: 0.5776\n",
            "Epoch [0], val_loss: 2.0184, val_acc: 0.5784\n",
            "Epoch [0], val_loss: 2.0176, val_acc: 0.5794\n",
            "Epoch [0], val_loss: 2.0167, val_acc: 0.5815\n",
            "Epoch [0], val_loss: 2.0159, val_acc: 0.5832\n",
            "Epoch [0], val_loss: 2.0150, val_acc: 0.5842\n",
            "Epoch [0], val_loss: 2.0142, val_acc: 0.5856\n",
            "Epoch [0], val_loss: 2.0133, val_acc: 0.5868\n",
            "Epoch [0], val_loss: 2.0124, val_acc: 0.5870\n",
            "Epoch [0], val_loss: 2.0115, val_acc: 0.5872\n",
            "Epoch [0], val_loss: 2.0106, val_acc: 0.5877\n",
            "Epoch [0], val_loss: 2.0098, val_acc: 0.5885\n",
            "Epoch [0], val_loss: 2.0089, val_acc: 0.5897\n",
            "Epoch [0], val_loss: 2.0080, val_acc: 0.5904\n",
            "Epoch [0], val_loss: 2.0072, val_acc: 0.5921\n",
            "Epoch [0], val_loss: 2.0063, val_acc: 0.5923\n",
            "Epoch [0], val_loss: 2.0055, val_acc: 0.5929\n",
            "Epoch [0], val_loss: 2.0046, val_acc: 0.5936\n",
            "Epoch [0], val_loss: 2.0039, val_acc: 0.5957\n",
            "Epoch [0], val_loss: 2.0030, val_acc: 0.5976\n",
            "Epoch [0], val_loss: 2.0021, val_acc: 0.5977\n",
            "Epoch [0], val_loss: 2.0012, val_acc: 0.5983\n",
            "Epoch [0], val_loss: 2.0004, val_acc: 0.5985\n",
            "Epoch [0], val_loss: 1.9996, val_acc: 0.5997\n",
            "Epoch [0], val_loss: 1.9988, val_acc: 0.6010\n",
            "Epoch [0], val_loss: 1.9980, val_acc: 0.6019\n",
            "Epoch [0], val_loss: 1.9971, val_acc: 0.6027\n",
            "Epoch [0], val_loss: 1.9963, val_acc: 0.6053\n",
            "Epoch [0], val_loss: 1.9954, val_acc: 0.6064\n",
            "Epoch [0], val_loss: 1.9945, val_acc: 0.6071\n",
            "Epoch [0], val_loss: 1.9937, val_acc: 0.6077\n",
            "Epoch [0], val_loss: 1.9928, val_acc: 0.6088\n",
            "Epoch [0], val_loss: 1.9921, val_acc: 0.6107\n",
            "Epoch [0], val_loss: 1.9913, val_acc: 0.6116\n",
            "Epoch [0], val_loss: 1.9905, val_acc: 0.6112\n",
            "Epoch [0], val_loss: 1.9897, val_acc: 0.6114\n",
            "Epoch [0], val_loss: 1.9889, val_acc: 0.6116\n",
            "Epoch [0], val_loss: 1.9881, val_acc: 0.6129\n",
            "Epoch [0], val_loss: 1.9872, val_acc: 0.6135\n",
            "Epoch [0], val_loss: 1.9864, val_acc: 0.6148\n",
            "Epoch [0], val_loss: 1.9856, val_acc: 0.6162\n",
            "Epoch [0], val_loss: 1.9848, val_acc: 0.6174\n",
            "Epoch [0], val_loss: 1.9840, val_acc: 0.6197\n",
            "Epoch [0], val_loss: 1.9832, val_acc: 0.6208\n",
            "Epoch [0], val_loss: 1.9822, val_acc: 0.6212\n",
            "Epoch [0], val_loss: 1.9814, val_acc: 0.6208\n",
            "Epoch [0], val_loss: 1.9806, val_acc: 0.6213\n",
            "Epoch [0], val_loss: 1.9797, val_acc: 0.6228\n",
            "Epoch [0], val_loss: 1.9789, val_acc: 0.6225\n",
            "Epoch [0], val_loss: 1.9779, val_acc: 0.6226\n",
            "Epoch [0], val_loss: 1.9771, val_acc: 0.6231\n",
            "Epoch [0], val_loss: 1.9762, val_acc: 0.6241\n",
            "Epoch [0], val_loss: 1.9754, val_acc: 0.6244\n",
            "Epoch [0], val_loss: 1.9746, val_acc: 0.6266\n",
            "Epoch [0], val_loss: 1.9737, val_acc: 0.6268\n",
            "Epoch [0], val_loss: 1.9728, val_acc: 0.6273\n",
            "Epoch [0], val_loss: 1.9720, val_acc: 0.6270\n",
            "Epoch [0], val_loss: 1.9712, val_acc: 0.6281\n",
            "Epoch [0], val_loss: 1.9704, val_acc: 0.6284\n",
            "Epoch [0], val_loss: 1.9696, val_acc: 0.6300\n",
            "Epoch [0], val_loss: 1.9687, val_acc: 0.6300\n",
            "Epoch [0], val_loss: 1.9679, val_acc: 0.6302\n",
            "Epoch [0], val_loss: 1.9671, val_acc: 0.6312\n",
            "Epoch [0], val_loss: 1.9663, val_acc: 0.6317\n",
            "Epoch [0], val_loss: 1.9655, val_acc: 0.6340\n",
            "Epoch [0], val_loss: 1.9647, val_acc: 0.6342\n",
            "Epoch [0], val_loss: 1.9638, val_acc: 0.6360\n",
            "Epoch [0], val_loss: 1.9630, val_acc: 0.6366\n",
            "Epoch [0], val_loss: 1.9621, val_acc: 0.6375\n",
            "Epoch [0], val_loss: 1.9613, val_acc: 0.6381\n",
            "Epoch [0], val_loss: 1.9604, val_acc: 0.6389\n",
            "Epoch [0], val_loss: 1.9596, val_acc: 0.6397\n",
            "Epoch [0], val_loss: 1.9588, val_acc: 0.6405\n",
            "Epoch [0], val_loss: 1.9580, val_acc: 0.6414\n",
            "Epoch [0], val_loss: 1.9573, val_acc: 0.6423\n",
            "Epoch [0], val_loss: 1.9565, val_acc: 0.6424\n",
            "Epoch [0], val_loss: 1.9557, val_acc: 0.6433\n",
            "Epoch [0], val_loss: 1.9549, val_acc: 0.6437\n",
            "Epoch [0], val_loss: 1.9541, val_acc: 0.6436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y35sD3ruVev",
        "outputId": "1bdb67ef-f84e-4392-9565-c297b9b8185b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 1.9533, val_acc: 0.6450\n",
            "Epoch [0], val_loss: 1.9524, val_acc: 0.6454\n",
            "Epoch [0], val_loss: 1.9515, val_acc: 0.6464\n",
            "Epoch [0], val_loss: 1.9508, val_acc: 0.6480\n",
            "Epoch [0], val_loss: 1.9499, val_acc: 0.6488\n",
            "Epoch [0], val_loss: 1.9490, val_acc: 0.6492\n",
            "Epoch [0], val_loss: 1.9482, val_acc: 0.6500\n",
            "Epoch [0], val_loss: 1.9475, val_acc: 0.6510\n",
            "Epoch [0], val_loss: 1.9466, val_acc: 0.6513\n",
            "Epoch [0], val_loss: 1.9458, val_acc: 0.6510\n",
            "Epoch [0], val_loss: 1.9450, val_acc: 0.6520\n",
            "Epoch [0], val_loss: 1.9442, val_acc: 0.6530\n",
            "Epoch [0], val_loss: 1.9435, val_acc: 0.6545\n",
            "Epoch [0], val_loss: 1.9426, val_acc: 0.6544\n",
            "Epoch [0], val_loss: 1.9418, val_acc: 0.6543\n",
            "Epoch [0], val_loss: 1.9409, val_acc: 0.6557\n",
            "Epoch [0], val_loss: 1.9401, val_acc: 0.6563\n",
            "Epoch [0], val_loss: 1.9394, val_acc: 0.6571\n",
            "Epoch [0], val_loss: 1.9386, val_acc: 0.6580\n",
            "Epoch [0], val_loss: 1.9378, val_acc: 0.6584\n",
            "Epoch [0], val_loss: 1.9370, val_acc: 0.6574\n",
            "Epoch [0], val_loss: 1.9362, val_acc: 0.6589\n",
            "Epoch [0], val_loss: 1.9353, val_acc: 0.6601\n",
            "Epoch [0], val_loss: 1.9345, val_acc: 0.6601\n",
            "Epoch [0], val_loss: 1.9337, val_acc: 0.6603\n",
            "Epoch [0], val_loss: 1.9329, val_acc: 0.6601\n",
            "Epoch [0], val_loss: 1.9321, val_acc: 0.6607\n",
            "Epoch [0], val_loss: 1.9312, val_acc: 0.6612\n",
            "Epoch [0], val_loss: 1.9304, val_acc: 0.6618\n",
            "Epoch [0], val_loss: 1.9296, val_acc: 0.6621\n",
            "Epoch [0], val_loss: 1.9288, val_acc: 0.6625\n",
            "Epoch [0], val_loss: 1.9280, val_acc: 0.6637\n",
            "Epoch [0], val_loss: 1.9271, val_acc: 0.6643\n",
            "Epoch [0], val_loss: 1.9264, val_acc: 0.6655\n",
            "Epoch [0], val_loss: 1.9256, val_acc: 0.6657\n",
            "Epoch [0], val_loss: 1.9247, val_acc: 0.6655\n",
            "Epoch [0], val_loss: 1.9239, val_acc: 0.6655\n",
            "Epoch [0], val_loss: 1.9232, val_acc: 0.6663\n",
            "Epoch [0], val_loss: 1.9223, val_acc: 0.6675\n",
            "Epoch [0], val_loss: 1.9216, val_acc: 0.6680\n",
            "Epoch [0], val_loss: 1.9208, val_acc: 0.6689\n",
            "Epoch [0], val_loss: 1.9200, val_acc: 0.6698\n",
            "Epoch [0], val_loss: 1.9192, val_acc: 0.6703\n",
            "Epoch [0], val_loss: 1.9184, val_acc: 0.6710\n",
            "Epoch [0], val_loss: 1.9176, val_acc: 0.6709\n",
            "Epoch [0], val_loss: 1.9167, val_acc: 0.6718\n",
            "Epoch [0], val_loss: 1.9159, val_acc: 0.6721\n",
            "Epoch [0], val_loss: 1.9152, val_acc: 0.6711\n",
            "Epoch [0], val_loss: 1.9145, val_acc: 0.6722\n",
            "Epoch [0], val_loss: 1.9137, val_acc: 0.6735\n",
            "Epoch [0], val_loss: 1.9130, val_acc: 0.6736\n",
            "Epoch [0], val_loss: 1.9122, val_acc: 0.6736\n",
            "Epoch [0], val_loss: 1.9114, val_acc: 0.6743\n",
            "Epoch [0], val_loss: 1.9107, val_acc: 0.6745\n",
            "Epoch [0], val_loss: 1.9099, val_acc: 0.6743\n",
            "Epoch [0], val_loss: 1.9091, val_acc: 0.6752\n",
            "Epoch [0], val_loss: 1.9083, val_acc: 0.6756\n",
            "Epoch [0], val_loss: 1.9076, val_acc: 0.6771\n",
            "Epoch [0], val_loss: 1.9068, val_acc: 0.6778\n",
            "Epoch [0], val_loss: 1.9061, val_acc: 0.6788\n",
            "Epoch [0], val_loss: 1.9053, val_acc: 0.6797\n",
            "Epoch [0], val_loss: 1.9046, val_acc: 0.6807\n",
            "Epoch [0], val_loss: 1.9038, val_acc: 0.6810\n",
            "Epoch [0], val_loss: 1.9031, val_acc: 0.6821\n",
            "Epoch [0], val_loss: 1.9023, val_acc: 0.6823\n",
            "Epoch [0], val_loss: 1.9016, val_acc: 0.6833\n",
            "Epoch [0], val_loss: 1.9008, val_acc: 0.6838\n",
            "Epoch [0], val_loss: 1.9000, val_acc: 0.6840\n",
            "Epoch [0], val_loss: 1.8992, val_acc: 0.6847\n",
            "Epoch [0], val_loss: 1.8984, val_acc: 0.6847\n",
            "Epoch [0], val_loss: 1.8977, val_acc: 0.6848\n",
            "Epoch [0], val_loss: 1.8970, val_acc: 0.6855\n",
            "Epoch [0], val_loss: 1.8962, val_acc: 0.6857\n",
            "Epoch [0], val_loss: 1.8953, val_acc: 0.6859\n",
            "Epoch [0], val_loss: 1.8946, val_acc: 0.6868\n",
            "Epoch [0], val_loss: 1.8938, val_acc: 0.6870\n",
            "Epoch [0], val_loss: 1.8931, val_acc: 0.6860\n",
            "Epoch [0], val_loss: 1.8923, val_acc: 0.6861\n",
            "Epoch [0], val_loss: 1.8915, val_acc: 0.6862\n",
            "Epoch [0], val_loss: 1.8908, val_acc: 0.6867\n",
            "Epoch [0], val_loss: 1.8900, val_acc: 0.6870\n",
            "Epoch [0], val_loss: 1.8893, val_acc: 0.6869\n",
            "Epoch [0], val_loss: 1.8885, val_acc: 0.6873\n",
            "Epoch [0], val_loss: 1.8877, val_acc: 0.6894\n",
            "Epoch [0], val_loss: 1.8870, val_acc: 0.6896\n",
            "Epoch [0], val_loss: 1.8863, val_acc: 0.6902\n",
            "Epoch [0], val_loss: 1.8855, val_acc: 0.6905\n",
            "Epoch [0], val_loss: 1.8847, val_acc: 0.6914\n",
            "Epoch [0], val_loss: 1.8839, val_acc: 0.6921\n",
            "Epoch [0], val_loss: 1.8831, val_acc: 0.6925\n",
            "Epoch [0], val_loss: 1.8823, val_acc: 0.6933\n",
            "Epoch [0], val_loss: 1.8816, val_acc: 0.6939\n",
            "Epoch [0], val_loss: 1.8809, val_acc: 0.6935\n",
            "Epoch [0], val_loss: 1.8801, val_acc: 0.6939\n",
            "Epoch [0], val_loss: 1.8793, val_acc: 0.6942\n",
            "Epoch [0], val_loss: 1.8786, val_acc: 0.6943\n",
            "Epoch [0], val_loss: 1.8778, val_acc: 0.6946\n",
            "Epoch [0], val_loss: 1.8771, val_acc: 0.6948\n",
            "Epoch [0], val_loss: 1.8764, val_acc: 0.6953\n",
            "Epoch [0], val_loss: 1.8757, val_acc: 0.6962\n",
            "Epoch [0], val_loss: 1.8750, val_acc: 0.6973\n",
            "Epoch [0], val_loss: 1.8742, val_acc: 0.6977\n",
            "Epoch [0], val_loss: 1.8734, val_acc: 0.6984\n",
            "Epoch [0], val_loss: 1.8726, val_acc: 0.6983\n",
            "Epoch [0], val_loss: 1.8719, val_acc: 0.6982\n",
            "Epoch [0], val_loss: 1.8711, val_acc: 0.6974\n",
            "Epoch [0], val_loss: 1.8703, val_acc: 0.6977\n",
            "Epoch [0], val_loss: 1.8696, val_acc: 0.6967\n",
            "Epoch [0], val_loss: 1.8688, val_acc: 0.6987\n",
            "Epoch [0], val_loss: 1.8681, val_acc: 0.6986\n",
            "Epoch [0], val_loss: 1.8673, val_acc: 0.6982\n",
            "Epoch [0], val_loss: 1.8665, val_acc: 0.6974\n",
            "Epoch [0], val_loss: 1.8657, val_acc: 0.6986\n",
            "Epoch [0], val_loss: 1.8650, val_acc: 0.6981\n",
            "Epoch [0], val_loss: 1.8642, val_acc: 0.6985\n",
            "Epoch [0], val_loss: 1.8636, val_acc: 0.6995\n",
            "Epoch [0], val_loss: 1.8628, val_acc: 0.7000\n",
            "Epoch [0], val_loss: 1.8621, val_acc: 0.6998\n",
            "Epoch [0], val_loss: 1.8613, val_acc: 0.7006\n",
            "Epoch [0], val_loss: 1.8607, val_acc: 0.7009\n",
            "Epoch [0], val_loss: 1.8599, val_acc: 0.7008\n",
            "Epoch [0], val_loss: 1.8592, val_acc: 0.7024\n",
            "Epoch [0], val_loss: 1.8584, val_acc: 0.7021\n",
            "Epoch [0], val_loss: 1.8577, val_acc: 0.7029\n",
            "Epoch [0], val_loss: 1.8570, val_acc: 0.7040\n",
            "Epoch [0], val_loss: 1.8564, val_acc: 0.7046\n",
            "Epoch [0], val_loss: 1.8557, val_acc: 0.7053\n",
            "Epoch [0], val_loss: 1.8550, val_acc: 0.7055\n",
            "Epoch [0], val_loss: 1.8542, val_acc: 0.7058\n",
            "Epoch [0], val_loss: 1.8535, val_acc: 0.7058\n",
            "Epoch [0], val_loss: 1.8527, val_acc: 0.7065\n",
            "Epoch [0], val_loss: 1.8520, val_acc: 0.7069\n",
            "Epoch [0], val_loss: 1.8513, val_acc: 0.7072\n",
            "Epoch [0], val_loss: 1.8506, val_acc: 0.7070\n",
            "Epoch [0], val_loss: 1.8498, val_acc: 0.7071\n",
            "Epoch [0], val_loss: 1.8491, val_acc: 0.7082\n",
            "Epoch [0], val_loss: 1.8483, val_acc: 0.7082\n",
            "Epoch [0], val_loss: 1.8476, val_acc: 0.7085\n",
            "Epoch [0], val_loss: 1.8468, val_acc: 0.7087\n",
            "Epoch [0], val_loss: 1.8460, val_acc: 0.7097\n",
            "Epoch [0], val_loss: 1.8453, val_acc: 0.7099\n",
            "Epoch [0], val_loss: 1.8446, val_acc: 0.7098\n",
            "Epoch [0], val_loss: 1.8439, val_acc: 0.7101\n",
            "Epoch [0], val_loss: 1.8431, val_acc: 0.7102\n",
            "Epoch [0], val_loss: 1.8423, val_acc: 0.7114\n",
            "Epoch [0], val_loss: 1.8416, val_acc: 0.7110\n",
            "Epoch [0], val_loss: 1.8408, val_acc: 0.7110\n",
            "Epoch [0], val_loss: 1.8402, val_acc: 0.7116\n",
            "Epoch [0], val_loss: 1.8394, val_acc: 0.7117\n",
            "Epoch [0], val_loss: 1.8386, val_acc: 0.7119\n",
            "Epoch [0], val_loss: 1.8379, val_acc: 0.7136\n",
            "Epoch [0], val_loss: 1.8371, val_acc: 0.7133\n",
            "Epoch [0], val_loss: 1.8364, val_acc: 0.7123\n",
            "Epoch [0], val_loss: 1.8357, val_acc: 0.7129\n",
            "Epoch [0], val_loss: 1.8350, val_acc: 0.7135\n",
            "Epoch [0], val_loss: 1.8343, val_acc: 0.7140\n",
            "Epoch [0], val_loss: 1.8336, val_acc: 0.7142\n",
            "Epoch [0], val_loss: 1.8328, val_acc: 0.7137\n",
            "Epoch [0], val_loss: 1.8321, val_acc: 0.7141\n",
            "Epoch [0], val_loss: 1.8313, val_acc: 0.7158\n",
            "Epoch [0], val_loss: 1.8306, val_acc: 0.7158\n",
            "Epoch [0], val_loss: 1.8300, val_acc: 0.7157\n",
            "Epoch [0], val_loss: 1.8292, val_acc: 0.7164\n",
            "Epoch [0], val_loss: 1.8285, val_acc: 0.7172\n",
            "Epoch [0], val_loss: 1.8278, val_acc: 0.7167\n",
            "Epoch [0], val_loss: 1.8271, val_acc: 0.7183\n",
            "Epoch [0], val_loss: 1.8265, val_acc: 0.7183\n",
            "Epoch [0], val_loss: 1.8257, val_acc: 0.7184\n",
            "Epoch [0], val_loss: 1.8250, val_acc: 0.7188\n",
            "Epoch [0], val_loss: 1.8243, val_acc: 0.7189\n",
            "Epoch [0], val_loss: 1.8235, val_acc: 0.7194\n",
            "Epoch [0], val_loss: 1.8228, val_acc: 0.7196\n",
            "Epoch [0], val_loss: 1.8221, val_acc: 0.7203\n",
            "Epoch [0], val_loss: 1.8214, val_acc: 0.7205\n",
            "Epoch [0], val_loss: 1.8207, val_acc: 0.7206\n",
            "Epoch [0], val_loss: 1.8200, val_acc: 0.7209\n",
            "Epoch [0], val_loss: 1.8194, val_acc: 0.7209\n",
            "Epoch [0], val_loss: 1.8187, val_acc: 0.7207\n",
            "Epoch [0], val_loss: 1.8180, val_acc: 0.7216\n",
            "Epoch [0], val_loss: 1.8173, val_acc: 0.7216\n",
            "Epoch [0], val_loss: 1.8166, val_acc: 0.7221\n",
            "Epoch [0], val_loss: 1.8159, val_acc: 0.7233\n",
            "Epoch [0], val_loss: 1.8151, val_acc: 0.7231\n",
            "Epoch [0], val_loss: 1.8144, val_acc: 0.7237\n",
            "Epoch [0], val_loss: 1.8136, val_acc: 0.7237\n",
            "Epoch [0], val_loss: 1.8130, val_acc: 0.7241\n",
            "Epoch [0], val_loss: 1.8122, val_acc: 0.7247\n",
            "Epoch [0], val_loss: 1.8115, val_acc: 0.7248\n",
            "Epoch [0], val_loss: 1.8107, val_acc: 0.7251\n",
            "Epoch [0], val_loss: 1.8100, val_acc: 0.7256\n",
            "Epoch [0], val_loss: 1.8093, val_acc: 0.7254\n",
            "Epoch [0], val_loss: 1.8086, val_acc: 0.7258\n",
            "Epoch [0], val_loss: 1.8080, val_acc: 0.7266\n",
            "Epoch [0], val_loss: 1.8072, val_acc: 0.7266\n",
            "Epoch [0], val_loss: 1.8066, val_acc: 0.7270\n",
            "Epoch [0], val_loss: 1.8059, val_acc: 0.7271\n",
            "Epoch [0], val_loss: 1.8052, val_acc: 0.7278\n",
            "Epoch [0], val_loss: 1.8045, val_acc: 0.7280\n",
            "Epoch [0], val_loss: 1.8038, val_acc: 0.7279\n",
            "Epoch [0], val_loss: 1.8031, val_acc: 0.7280\n",
            "Epoch [0], val_loss: 1.8024, val_acc: 0.7280\n",
            "Epoch [0], val_loss: 1.8017, val_acc: 0.7287\n",
            "Epoch [0], val_loss: 1.8010, val_acc: 0.7292\n",
            "Epoch [0], val_loss: 1.8003, val_acc: 0.7290\n",
            "Epoch [0], val_loss: 1.7997, val_acc: 0.7293\n",
            "Epoch [0], val_loss: 1.7990, val_acc: 0.7297\n",
            "Epoch [0], val_loss: 1.7982, val_acc: 0.7295\n",
            "Epoch [0], val_loss: 1.7975, val_acc: 0.7304\n",
            "Epoch [0], val_loss: 1.7969, val_acc: 0.7307\n",
            "Epoch [0], val_loss: 1.7961, val_acc: 0.7308\n",
            "Epoch [0], val_loss: 1.7954, val_acc: 0.7306\n",
            "Epoch [0], val_loss: 1.7948, val_acc: 0.7302\n",
            "Epoch [0], val_loss: 1.7941, val_acc: 0.7309\n",
            "Epoch [0], val_loss: 1.7934, val_acc: 0.7305\n",
            "Epoch [0], val_loss: 1.7927, val_acc: 0.7312\n",
            "Epoch [0], val_loss: 1.7921, val_acc: 0.7314\n",
            "Epoch [0], val_loss: 1.7913, val_acc: 0.7309\n",
            "Epoch [0], val_loss: 1.7906, val_acc: 0.7310\n",
            "Epoch [0], val_loss: 1.7899, val_acc: 0.7315\n",
            "Epoch [0], val_loss: 1.7892, val_acc: 0.7318\n",
            "Epoch [0], val_loss: 1.7885, val_acc: 0.7322\n",
            "Epoch [0], val_loss: 1.7879, val_acc: 0.7320\n",
            "Epoch [0], val_loss: 1.7872, val_acc: 0.7326\n",
            "Epoch [0], val_loss: 1.7865, val_acc: 0.7329\n",
            "Epoch [0], val_loss: 1.7858, val_acc: 0.7332\n",
            "Epoch [0], val_loss: 1.7851, val_acc: 0.7332\n",
            "Epoch [0], val_loss: 1.7844, val_acc: 0.7337\n",
            "Epoch [0], val_loss: 1.7837, val_acc: 0.7340\n",
            "Epoch [0], val_loss: 1.7830, val_acc: 0.7336\n",
            "Epoch [0], val_loss: 1.7823, val_acc: 0.7336\n",
            "Epoch [0], val_loss: 1.7817, val_acc: 0.7341\n",
            "Epoch [0], val_loss: 1.7810, val_acc: 0.7342\n",
            "Epoch [0], val_loss: 1.7803, val_acc: 0.7345\n",
            "Epoch [0], val_loss: 1.7797, val_acc: 0.7345\n",
            "Epoch [0], val_loss: 1.7790, val_acc: 0.7344\n",
            "Epoch [0], val_loss: 1.7782, val_acc: 0.7345\n",
            "Epoch [0], val_loss: 1.7775, val_acc: 0.7353\n",
            "Epoch [0], val_loss: 1.7768, val_acc: 0.7355\n",
            "Epoch [0], val_loss: 1.7761, val_acc: 0.7356\n",
            "Epoch [0], val_loss: 1.7754, val_acc: 0.7354\n",
            "Epoch [0], val_loss: 1.7748, val_acc: 0.7353\n",
            "Epoch [0], val_loss: 1.7741, val_acc: 0.7352\n",
            "Epoch [0], val_loss: 1.7734, val_acc: 0.7358\n",
            "Epoch [0], val_loss: 1.7727, val_acc: 0.7357\n",
            "Epoch [0], val_loss: 1.7720, val_acc: 0.7354\n",
            "Epoch [0], val_loss: 1.7713, val_acc: 0.7363\n",
            "Epoch [0], val_loss: 1.7706, val_acc: 0.7366\n",
            "Epoch [0], val_loss: 1.7699, val_acc: 0.7366\n",
            "Epoch [0], val_loss: 1.7693, val_acc: 0.7369\n",
            "Epoch [0], val_loss: 1.7686, val_acc: 0.7373\n",
            "Epoch [0], val_loss: 1.7679, val_acc: 0.7377\n",
            "Epoch [0], val_loss: 1.7672, val_acc: 0.7381\n",
            "Epoch [0], val_loss: 1.7666, val_acc: 0.7385\n",
            "Epoch [0], val_loss: 1.7659, val_acc: 0.7387\n",
            "Epoch [0], val_loss: 1.7652, val_acc: 0.7389\n",
            "Epoch [0], val_loss: 1.7645, val_acc: 0.7393\n",
            "Epoch [0], val_loss: 1.7638, val_acc: 0.7398\n",
            "Epoch [0], val_loss: 1.7632, val_acc: 0.7399\n",
            "Epoch [0], val_loss: 1.7625, val_acc: 0.7402\n",
            "Epoch [0], val_loss: 1.7619, val_acc: 0.7406\n",
            "Epoch [0], val_loss: 1.7612, val_acc: 0.7402\n",
            "Epoch [0], val_loss: 1.7606, val_acc: 0.7403\n",
            "Epoch [0], val_loss: 1.7599, val_acc: 0.7408\n",
            "Epoch [0], val_loss: 1.7592, val_acc: 0.7412\n",
            "Epoch [0], val_loss: 1.7585, val_acc: 0.7410\n",
            "Epoch [0], val_loss: 1.7579, val_acc: 0.7415\n",
            "Epoch [0], val_loss: 1.7572, val_acc: 0.7417\n",
            "Epoch [0], val_loss: 1.7566, val_acc: 0.7419\n",
            "Epoch [0], val_loss: 1.7560, val_acc: 0.7426\n",
            "Epoch [0], val_loss: 1.7553, val_acc: 0.7422\n",
            "Epoch [0], val_loss: 1.7547, val_acc: 0.7426\n",
            "Epoch [0], val_loss: 1.7540, val_acc: 0.7422\n",
            "Epoch [0], val_loss: 1.7533, val_acc: 0.7423\n",
            "Epoch [0], val_loss: 1.7526, val_acc: 0.7431\n",
            "Epoch [0], val_loss: 1.7520, val_acc: 0.7427\n",
            "Epoch [0], val_loss: 1.7513, val_acc: 0.7431\n",
            "Epoch [0], val_loss: 1.7508, val_acc: 0.7438\n",
            "Epoch [0], val_loss: 1.7501, val_acc: 0.7435\n",
            "Epoch [0], val_loss: 1.7494, val_acc: 0.7434\n",
            "Epoch [0], val_loss: 1.7488, val_acc: 0.7441\n",
            "Epoch [0], val_loss: 1.7481, val_acc: 0.7436\n",
            "Epoch [0], val_loss: 1.7475, val_acc: 0.7447\n",
            "Epoch [0], val_loss: 1.7468, val_acc: 0.7451\n",
            "Epoch [0], val_loss: 1.7461, val_acc: 0.7452\n",
            "Epoch [0], val_loss: 1.7455, val_acc: 0.7453\n",
            "Epoch [0], val_loss: 1.7447, val_acc: 0.7454\n",
            "Epoch [0], val_loss: 1.7441, val_acc: 0.7450\n",
            "Epoch [0], val_loss: 1.7434, val_acc: 0.7451\n",
            "Epoch [0], val_loss: 1.7427, val_acc: 0.7450\n",
            "Epoch [0], val_loss: 1.7420, val_acc: 0.7453\n",
            "Epoch [0], val_loss: 1.7414, val_acc: 0.7455\n",
            "Epoch [0], val_loss: 1.7408, val_acc: 0.7456\n",
            "Epoch [0], val_loss: 1.7401, val_acc: 0.7458\n",
            "Epoch [0], val_loss: 1.7395, val_acc: 0.7457\n",
            "Epoch [0], val_loss: 1.7388, val_acc: 0.7461\n",
            "Epoch [0], val_loss: 1.7382, val_acc: 0.7460\n",
            "Epoch [0], val_loss: 1.7375, val_acc: 0.7466\n",
            "Epoch [0], val_loss: 1.7369, val_acc: 0.7468\n",
            "Epoch [0], val_loss: 1.7362, val_acc: 0.7464\n",
            "Epoch [0], val_loss: 1.7356, val_acc: 0.7472\n",
            "Epoch [0], val_loss: 1.7349, val_acc: 0.7474\n",
            "Epoch [0], val_loss: 1.7343, val_acc: 0.7479\n",
            "Epoch [0], val_loss: 1.7337, val_acc: 0.7485\n",
            "Epoch [0], val_loss: 1.7330, val_acc: 0.7485\n",
            "Epoch [0], val_loss: 1.7323, val_acc: 0.7488\n",
            "Epoch [0], val_loss: 1.7317, val_acc: 0.7486\n",
            "Epoch [0], val_loss: 1.7311, val_acc: 0.7485\n",
            "Epoch [0], val_loss: 1.7304, val_acc: 0.7493\n",
            "Epoch [0], val_loss: 1.7298, val_acc: 0.7487\n",
            "Epoch [0], val_loss: 1.7292, val_acc: 0.7486\n",
            "Epoch [0], val_loss: 1.7285, val_acc: 0.7487\n",
            "Epoch [0], val_loss: 1.7278, val_acc: 0.7497\n",
            "Epoch [0], val_loss: 1.7272, val_acc: 0.7503\n",
            "Epoch [0], val_loss: 1.7266, val_acc: 0.7505\n",
            "Epoch [0], val_loss: 1.7259, val_acc: 0.7502\n",
            "Epoch [0], val_loss: 1.7251, val_acc: 0.7505\n",
            "Epoch [0], val_loss: 1.7246, val_acc: 0.7503\n",
            "Epoch [0], val_loss: 1.7239, val_acc: 0.7499\n",
            "Epoch [0], val_loss: 1.7233, val_acc: 0.7505\n",
            "Epoch [0], val_loss: 1.7226, val_acc: 0.7501\n",
            "Epoch [0], val_loss: 1.7220, val_acc: 0.7499\n",
            "Epoch [0], val_loss: 1.7213, val_acc: 0.7498\n",
            "Epoch [0], val_loss: 1.7207, val_acc: 0.7502\n",
            "Epoch [0], val_loss: 1.7200, val_acc: 0.7503\n",
            "Epoch [0], val_loss: 1.7194, val_acc: 0.7500\n",
            "Epoch [0], val_loss: 1.7188, val_acc: 0.7502\n",
            "Epoch [0], val_loss: 1.7182, val_acc: 0.7502\n",
            "Epoch [0], val_loss: 1.7175, val_acc: 0.7500\n",
            "Epoch [0], val_loss: 1.7168, val_acc: 0.7507\n",
            "Epoch [0], val_loss: 1.7162, val_acc: 0.7502\n",
            "Epoch [0], val_loss: 1.7155, val_acc: 0.7504\n",
            "Epoch [0], val_loss: 1.7149, val_acc: 0.7512\n",
            "Epoch [0], val_loss: 1.7142, val_acc: 0.7508\n",
            "Epoch [0], val_loss: 1.7136, val_acc: 0.7507\n",
            "Epoch [0], val_loss: 1.7130, val_acc: 0.7511\n",
            "Epoch [0], val_loss: 1.7123, val_acc: 0.7513\n",
            "Epoch [0], val_loss: 1.7117, val_acc: 0.7513\n",
            "Epoch [0], val_loss: 1.7111, val_acc: 0.7514\n",
            "Epoch [0], val_loss: 1.7104, val_acc: 0.7513\n",
            "Epoch [0], val_loss: 1.7098, val_acc: 0.7516\n",
            "Epoch [0], val_loss: 1.7092, val_acc: 0.7516\n",
            "Epoch [0], val_loss: 1.7086, val_acc: 0.7518\n",
            "Epoch [0], val_loss: 1.7080, val_acc: 0.7518\n",
            "Epoch [0], val_loss: 1.7074, val_acc: 0.7516\n",
            "Epoch [0], val_loss: 1.7068, val_acc: 0.7522\n",
            "Epoch [0], val_loss: 1.7062, val_acc: 0.7529\n",
            "Epoch [0], val_loss: 1.7056, val_acc: 0.7535\n",
            "Epoch [0], val_loss: 1.7049, val_acc: 0.7532\n",
            "Epoch [0], val_loss: 1.7043, val_acc: 0.7530\n",
            "Epoch [0], val_loss: 1.7037, val_acc: 0.7532\n",
            "Epoch [0], val_loss: 1.7031, val_acc: 0.7530\n",
            "Epoch [0], val_loss: 1.7024, val_acc: 0.7528\n",
            "Epoch [0], val_loss: 1.7018, val_acc: 0.7542\n",
            "Epoch [0], val_loss: 1.7011, val_acc: 0.7535\n",
            "Epoch [0], val_loss: 1.7005, val_acc: 0.7533\n",
            "Epoch [0], val_loss: 1.6999, val_acc: 0.7537\n",
            "Epoch [0], val_loss: 1.6992, val_acc: 0.7536\n",
            "Epoch [0], val_loss: 1.6987, val_acc: 0.7538\n",
            "Epoch [0], val_loss: 1.6981, val_acc: 0.7539\n",
            "Epoch [0], val_loss: 1.6974, val_acc: 0.7538\n",
            "Epoch [0], val_loss: 1.6968, val_acc: 0.7541\n",
            "Epoch [0], val_loss: 1.6961, val_acc: 0.7542\n",
            "Epoch [0], val_loss: 1.6955, val_acc: 0.7544\n",
            "Epoch [0], val_loss: 1.6948, val_acc: 0.7545\n",
            "Epoch [0], val_loss: 1.6942, val_acc: 0.7538\n",
            "Epoch [0], val_loss: 1.6936, val_acc: 0.7545\n",
            "Epoch [0], val_loss: 1.6930, val_acc: 0.7547\n",
            "Epoch [0], val_loss: 1.6924, val_acc: 0.7553\n",
            "Epoch [0], val_loss: 1.6918, val_acc: 0.7549\n",
            "Epoch [0], val_loss: 1.6912, val_acc: 0.7550\n",
            "Epoch [0], val_loss: 1.6905, val_acc: 0.7554\n",
            "Epoch [0], val_loss: 1.6899, val_acc: 0.7554\n",
            "Epoch [0], val_loss: 1.6894, val_acc: 0.7559\n",
            "Epoch [0], val_loss: 1.6888, val_acc: 0.7557\n",
            "Epoch [0], val_loss: 1.6881, val_acc: 0.7565\n",
            "Epoch [0], val_loss: 1.6875, val_acc: 0.7565\n",
            "Epoch [0], val_loss: 1.6869, val_acc: 0.7566\n",
            "Epoch [0], val_loss: 1.6863, val_acc: 0.7570\n",
            "Epoch [0], val_loss: 1.6857, val_acc: 0.7567\n",
            "Epoch [0], val_loss: 1.6851, val_acc: 0.7568\n",
            "Epoch [0], val_loss: 1.6845, val_acc: 0.7571\n",
            "Epoch [0], val_loss: 1.6838, val_acc: 0.7572\n",
            "Epoch [0], val_loss: 1.6832, val_acc: 0.7570\n",
            "Epoch [0], val_loss: 1.6826, val_acc: 0.7571\n",
            "Epoch [0], val_loss: 1.6820, val_acc: 0.7568\n",
            "Epoch [0], val_loss: 1.6813, val_acc: 0.7559\n",
            "Epoch [0], val_loss: 1.6807, val_acc: 0.7566\n",
            "Epoch [0], val_loss: 1.6801, val_acc: 0.7557\n",
            "Epoch [0], val_loss: 1.6795, val_acc: 0.7563\n",
            "Epoch [0], val_loss: 1.6789, val_acc: 0.7564\n",
            "Epoch [0], val_loss: 1.6783, val_acc: 0.7566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrHHR0hXvGqj",
        "outputId": "fc6373dd-7795-47fb-ec8e-d8f4f251cade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 1.6778, val_acc: 0.7565\n",
            "Epoch [0], val_loss: 1.6772, val_acc: 0.7568\n",
            "Epoch [0], val_loss: 1.6766, val_acc: 0.7573\n",
            "Epoch [0], val_loss: 1.6760, val_acc: 0.7569\n",
            "Epoch [0], val_loss: 1.6754, val_acc: 0.7569\n",
            "Epoch [0], val_loss: 1.6748, val_acc: 0.7569\n",
            "Epoch [0], val_loss: 1.6742, val_acc: 0.7574\n",
            "Epoch [0], val_loss: 1.6737, val_acc: 0.7574\n",
            "Epoch [0], val_loss: 1.6731, val_acc: 0.7580\n",
            "Epoch [0], val_loss: 1.6725, val_acc: 0.7582\n",
            "Epoch [0], val_loss: 1.6719, val_acc: 0.7578\n",
            "Epoch [0], val_loss: 1.6713, val_acc: 0.7577\n",
            "Epoch [0], val_loss: 1.6707, val_acc: 0.7578\n",
            "Epoch [0], val_loss: 1.6701, val_acc: 0.7581\n",
            "Epoch [0], val_loss: 1.6694, val_acc: 0.7581\n",
            "Epoch [0], val_loss: 1.6688, val_acc: 0.7581\n",
            "Epoch [0], val_loss: 1.6683, val_acc: 0.7585\n",
            "Epoch [0], val_loss: 1.6677, val_acc: 0.7585\n",
            "Epoch [0], val_loss: 1.6670, val_acc: 0.7587\n",
            "Epoch [0], val_loss: 1.6665, val_acc: 0.7585\n",
            "Epoch [0], val_loss: 1.6659, val_acc: 0.7586\n",
            "Epoch [0], val_loss: 1.6653, val_acc: 0.7587\n",
            "Epoch [0], val_loss: 1.6647, val_acc: 0.7592\n",
            "Epoch [0], val_loss: 1.6641, val_acc: 0.7590\n",
            "Epoch [0], val_loss: 1.6635, val_acc: 0.7597\n",
            "Epoch [0], val_loss: 1.6629, val_acc: 0.7592\n",
            "Epoch [0], val_loss: 1.6623, val_acc: 0.7594\n",
            "Epoch [0], val_loss: 1.6617, val_acc: 0.7594\n",
            "Epoch [0], val_loss: 1.6610, val_acc: 0.7592\n",
            "Epoch [0], val_loss: 1.6605, val_acc: 0.7593\n",
            "Epoch [0], val_loss: 1.6598, val_acc: 0.7593\n",
            "Epoch [0], val_loss: 1.6593, val_acc: 0.7601\n",
            "Epoch [0], val_loss: 1.6587, val_acc: 0.7602\n",
            "Epoch [0], val_loss: 1.6581, val_acc: 0.7608\n",
            "Epoch [0], val_loss: 1.6575, val_acc: 0.7610\n",
            "Epoch [0], val_loss: 1.6569, val_acc: 0.7613\n",
            "Epoch [0], val_loss: 1.6563, val_acc: 0.7613\n",
            "Epoch [0], val_loss: 1.6557, val_acc: 0.7615\n",
            "Epoch [0], val_loss: 1.6552, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6546, val_acc: 0.7613\n",
            "Epoch [0], val_loss: 1.6540, val_acc: 0.7612\n",
            "Epoch [0], val_loss: 1.6534, val_acc: 0.7615\n",
            "Epoch [0], val_loss: 1.6528, val_acc: 0.7616\n",
            "Epoch [0], val_loss: 1.6523, val_acc: 0.7616\n",
            "Epoch [0], val_loss: 1.6516, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6510, val_acc: 0.7620\n",
            "Epoch [0], val_loss: 1.6504, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6498, val_acc: 0.7619\n",
            "Epoch [0], val_loss: 1.6492, val_acc: 0.7624\n",
            "Epoch [0], val_loss: 1.6486, val_acc: 0.7615\n",
            "Epoch [0], val_loss: 1.6480, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6474, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6468, val_acc: 0.7618\n",
            "Epoch [0], val_loss: 1.6462, val_acc: 0.7617\n",
            "Epoch [0], val_loss: 1.6457, val_acc: 0.7616\n",
            "Epoch [0], val_loss: 1.6451, val_acc: 0.7611\n",
            "Epoch [0], val_loss: 1.6445, val_acc: 0.7613\n",
            "Epoch [0], val_loss: 1.6439, val_acc: 0.7617\n",
            "Epoch [0], val_loss: 1.6433, val_acc: 0.7625\n",
            "Epoch [0], val_loss: 1.6427, val_acc: 0.7624\n",
            "Epoch [0], val_loss: 1.6421, val_acc: 0.7625\n",
            "Epoch [0], val_loss: 1.6415, val_acc: 0.7619\n",
            "Epoch [0], val_loss: 1.6409, val_acc: 0.7621\n",
            "Epoch [0], val_loss: 1.6403, val_acc: 0.7629\n",
            "Epoch [0], val_loss: 1.6397, val_acc: 0.7630\n",
            "Epoch [0], val_loss: 1.6392, val_acc: 0.7630\n",
            "Epoch [0], val_loss: 1.6387, val_acc: 0.7632\n",
            "Epoch [0], val_loss: 1.6381, val_acc: 0.7634\n",
            "Epoch [0], val_loss: 1.6375, val_acc: 0.7634\n",
            "Epoch [0], val_loss: 1.6369, val_acc: 0.7640\n",
            "Epoch [0], val_loss: 1.6364, val_acc: 0.7641\n",
            "Epoch [0], val_loss: 1.6358, val_acc: 0.7645\n",
            "Epoch [0], val_loss: 1.6352, val_acc: 0.7646\n",
            "Epoch [0], val_loss: 1.6346, val_acc: 0.7644\n",
            "Epoch [0], val_loss: 1.6340, val_acc: 0.7648\n",
            "Epoch [0], val_loss: 1.6334, val_acc: 0.7648\n",
            "Epoch [0], val_loss: 1.6328, val_acc: 0.7645\n",
            "Epoch [0], val_loss: 1.6323, val_acc: 0.7645\n",
            "Epoch [0], val_loss: 1.6317, val_acc: 0.7646\n",
            "Epoch [0], val_loss: 1.6312, val_acc: 0.7644\n",
            "Epoch [0], val_loss: 1.6306, val_acc: 0.7647\n",
            "Epoch [0], val_loss: 1.6300, val_acc: 0.7647\n",
            "Epoch [0], val_loss: 1.6294, val_acc: 0.7650\n",
            "Epoch [0], val_loss: 1.6288, val_acc: 0.7651\n",
            "Epoch [0], val_loss: 1.6282, val_acc: 0.7649\n",
            "Epoch [0], val_loss: 1.6277, val_acc: 0.7650\n",
            "Epoch [0], val_loss: 1.6271, val_acc: 0.7651\n",
            "Epoch [0], val_loss: 1.6265, val_acc: 0.7651\n",
            "Epoch [0], val_loss: 1.6259, val_acc: 0.7651\n",
            "Epoch [0], val_loss: 1.6254, val_acc: 0.7648\n",
            "Epoch [0], val_loss: 1.6248, val_acc: 0.7644\n",
            "Epoch [0], val_loss: 1.6242, val_acc: 0.7649\n",
            "Epoch [0], val_loss: 1.6237, val_acc: 0.7649\n",
            "Epoch [0], val_loss: 1.6231, val_acc: 0.7647\n",
            "Epoch [0], val_loss: 1.6225, val_acc: 0.7646\n",
            "Epoch [0], val_loss: 1.6220, val_acc: 0.7649\n",
            "Epoch [0], val_loss: 1.6214, val_acc: 0.7654\n",
            "Epoch [0], val_loss: 1.6209, val_acc: 0.7658\n",
            "Epoch [0], val_loss: 1.6203, val_acc: 0.7656\n",
            "Epoch [0], val_loss: 1.6198, val_acc: 0.7661\n",
            "Epoch [0], val_loss: 1.6192, val_acc: 0.7662\n",
            "Epoch [0], val_loss: 1.6186, val_acc: 0.7665\n",
            "Epoch [0], val_loss: 1.6181, val_acc: 0.7662\n",
            "Epoch [0], val_loss: 1.6175, val_acc: 0.7662\n",
            "Epoch [0], val_loss: 1.6169, val_acc: 0.7668\n",
            "Epoch [0], val_loss: 1.6163, val_acc: 0.7666\n",
            "Epoch [0], val_loss: 1.6158, val_acc: 0.7670\n",
            "Epoch [0], val_loss: 1.6152, val_acc: 0.7666\n",
            "Epoch [0], val_loss: 1.6146, val_acc: 0.7665\n",
            "Epoch [0], val_loss: 1.6140, val_acc: 0.7666\n",
            "Epoch [0], val_loss: 1.6135, val_acc: 0.7674\n",
            "Epoch [0], val_loss: 1.6130, val_acc: 0.7674\n",
            "Epoch [0], val_loss: 1.6124, val_acc: 0.7676\n",
            "Epoch [0], val_loss: 1.6118, val_acc: 0.7678\n",
            "Epoch [0], val_loss: 1.6112, val_acc: 0.7682\n",
            "Epoch [0], val_loss: 1.6107, val_acc: 0.7682\n",
            "Epoch [0], val_loss: 1.6102, val_acc: 0.7679\n",
            "Epoch [0], val_loss: 1.6097, val_acc: 0.7681\n",
            "Epoch [0], val_loss: 1.6091, val_acc: 0.7683\n",
            "Epoch [0], val_loss: 1.6086, val_acc: 0.7687\n",
            "Epoch [0], val_loss: 1.6080, val_acc: 0.7685\n",
            "Epoch [0], val_loss: 1.6075, val_acc: 0.7686\n",
            "Epoch [0], val_loss: 1.6069, val_acc: 0.7688\n",
            "Epoch [0], val_loss: 1.6063, val_acc: 0.7688\n",
            "Epoch [0], val_loss: 1.6058, val_acc: 0.7690\n",
            "Epoch [0], val_loss: 1.6053, val_acc: 0.7687\n",
            "Epoch [0], val_loss: 1.6047, val_acc: 0.7691\n",
            "Epoch [0], val_loss: 1.6041, val_acc: 0.7689\n",
            "Epoch [0], val_loss: 1.6035, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.6030, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.6025, val_acc: 0.7691\n",
            "Epoch [0], val_loss: 1.6019, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.6013, val_acc: 0.7694\n",
            "Epoch [0], val_loss: 1.6007, val_acc: 0.7691\n",
            "Epoch [0], val_loss: 1.6002, val_acc: 0.7693\n",
            "Epoch [0], val_loss: 1.5997, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5991, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5986, val_acc: 0.7689\n",
            "Epoch [0], val_loss: 1.5980, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5975, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5969, val_acc: 0.7691\n",
            "Epoch [0], val_loss: 1.5964, val_acc: 0.7693\n",
            "Epoch [0], val_loss: 1.5958, val_acc: 0.7694\n",
            "Epoch [0], val_loss: 1.5953, val_acc: 0.7695\n",
            "Epoch [0], val_loss: 1.5947, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5942, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5936, val_acc: 0.7692\n",
            "Epoch [0], val_loss: 1.5931, val_acc: 0.7699\n",
            "Epoch [0], val_loss: 1.5926, val_acc: 0.7698\n",
            "Epoch [0], val_loss: 1.5920, val_acc: 0.7698\n",
            "Epoch [0], val_loss: 1.5915, val_acc: 0.7699\n",
            "Epoch [0], val_loss: 1.5909, val_acc: 0.7697\n",
            "Epoch [0], val_loss: 1.5904, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5899, val_acc: 0.7697\n",
            "Epoch [0], val_loss: 1.5893, val_acc: 0.7694\n",
            "Epoch [0], val_loss: 1.5888, val_acc: 0.7693\n",
            "Epoch [0], val_loss: 1.5882, val_acc: 0.7694\n",
            "Epoch [0], val_loss: 1.5877, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5872, val_acc: 0.7697\n",
            "Epoch [0], val_loss: 1.5866, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5860, val_acc: 0.7700\n",
            "Epoch [0], val_loss: 1.5855, val_acc: 0.7702\n",
            "Epoch [0], val_loss: 1.5850, val_acc: 0.7698\n",
            "Epoch [0], val_loss: 1.5844, val_acc: 0.7699\n",
            "Epoch [0], val_loss: 1.5839, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5834, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5829, val_acc: 0.7698\n",
            "Epoch [0], val_loss: 1.5824, val_acc: 0.7695\n",
            "Epoch [0], val_loss: 1.5818, val_acc: 0.7696\n",
            "Epoch [0], val_loss: 1.5814, val_acc: 0.7698\n",
            "Epoch [0], val_loss: 1.5808, val_acc: 0.7701\n",
            "Epoch [0], val_loss: 1.5803, val_acc: 0.7704\n",
            "Epoch [0], val_loss: 1.5798, val_acc: 0.7707\n",
            "Epoch [0], val_loss: 1.5792, val_acc: 0.7704\n",
            "Epoch [0], val_loss: 1.5788, val_acc: 0.7705\n",
            "Epoch [0], val_loss: 1.5783, val_acc: 0.7706\n",
            "Epoch [0], val_loss: 1.5777, val_acc: 0.7706\n",
            "Epoch [0], val_loss: 1.5772, val_acc: 0.7712\n",
            "Epoch [0], val_loss: 1.5767, val_acc: 0.7715\n",
            "Epoch [0], val_loss: 1.5761, val_acc: 0.7715\n",
            "Epoch [0], val_loss: 1.5756, val_acc: 0.7711\n",
            "Epoch [0], val_loss: 1.5751, val_acc: 0.7716\n",
            "Epoch [0], val_loss: 1.5745, val_acc: 0.7715\n",
            "Epoch [0], val_loss: 1.5740, val_acc: 0.7716\n",
            "Epoch [0], val_loss: 1.5734, val_acc: 0.7715\n",
            "Epoch [0], val_loss: 1.5729, val_acc: 0.7719\n",
            "Epoch [0], val_loss: 1.5724, val_acc: 0.7718\n",
            "Epoch [0], val_loss: 1.5718, val_acc: 0.7718\n",
            "Epoch [0], val_loss: 1.5713, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5708, val_acc: 0.7719\n",
            "Epoch [0], val_loss: 1.5703, val_acc: 0.7721\n",
            "Epoch [0], val_loss: 1.5697, val_acc: 0.7721\n",
            "Epoch [0], val_loss: 1.5692, val_acc: 0.7717\n",
            "Epoch [0], val_loss: 1.5687, val_acc: 0.7717\n",
            "Epoch [0], val_loss: 1.5681, val_acc: 0.7717\n",
            "Epoch [0], val_loss: 1.5676, val_acc: 0.7715\n",
            "Epoch [0], val_loss: 1.5671, val_acc: 0.7717\n",
            "Epoch [0], val_loss: 1.5666, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5661, val_acc: 0.7721\n",
            "Epoch [0], val_loss: 1.5656, val_acc: 0.7722\n",
            "Epoch [0], val_loss: 1.5651, val_acc: 0.7724\n",
            "Epoch [0], val_loss: 1.5646, val_acc: 0.7717\n",
            "Epoch [0], val_loss: 1.5641, val_acc: 0.7719\n",
            "Epoch [0], val_loss: 1.5635, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5629, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5624, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5619, val_acc: 0.7723\n",
            "Epoch [0], val_loss: 1.5613, val_acc: 0.7723\n",
            "Epoch [0], val_loss: 1.5608, val_acc: 0.7720\n",
            "Epoch [0], val_loss: 1.5603, val_acc: 0.7723\n",
            "Epoch [0], val_loss: 1.5598, val_acc: 0.7725\n",
            "Epoch [0], val_loss: 1.5593, val_acc: 0.7726\n",
            "Epoch [0], val_loss: 1.5587, val_acc: 0.7728\n",
            "Epoch [0], val_loss: 1.5582, val_acc: 0.7731\n",
            "Epoch [0], val_loss: 1.5577, val_acc: 0.7728\n",
            "Epoch [0], val_loss: 1.5572, val_acc: 0.7730\n",
            "Epoch [0], val_loss: 1.5567, val_acc: 0.7735\n",
            "Epoch [0], val_loss: 1.5562, val_acc: 0.7741\n",
            "Epoch [0], val_loss: 1.5557, val_acc: 0.7736\n",
            "Epoch [0], val_loss: 1.5552, val_acc: 0.7735\n",
            "Epoch [0], val_loss: 1.5547, val_acc: 0.7732\n",
            "Epoch [0], val_loss: 1.5542, val_acc: 0.7733\n",
            "Epoch [0], val_loss: 1.5537, val_acc: 0.7734\n",
            "Epoch [0], val_loss: 1.5532, val_acc: 0.7739\n",
            "Epoch [0], val_loss: 1.5526, val_acc: 0.7733\n",
            "Epoch [0], val_loss: 1.5522, val_acc: 0.7737\n",
            "Epoch [0], val_loss: 1.5517, val_acc: 0.7739\n",
            "Epoch [0], val_loss: 1.5512, val_acc: 0.7737\n",
            "Epoch [0], val_loss: 1.5506, val_acc: 0.7738\n",
            "Epoch [0], val_loss: 1.5502, val_acc: 0.7738\n",
            "Epoch [0], val_loss: 1.5496, val_acc: 0.7738\n",
            "Epoch [0], val_loss: 1.5491, val_acc: 0.7737\n",
            "Epoch [0], val_loss: 1.5486, val_acc: 0.7740\n",
            "Epoch [0], val_loss: 1.5481, val_acc: 0.7736\n",
            "Epoch [0], val_loss: 1.5476, val_acc: 0.7743\n",
            "Epoch [0], val_loss: 1.5471, val_acc: 0.7737\n",
            "Epoch [0], val_loss: 1.5466, val_acc: 0.7740\n",
            "Epoch [0], val_loss: 1.5461, val_acc: 0.7741\n",
            "Epoch [0], val_loss: 1.5456, val_acc: 0.7743\n",
            "Epoch [0], val_loss: 1.5451, val_acc: 0.7746\n",
            "Epoch [0], val_loss: 1.5446, val_acc: 0.7753\n",
            "Epoch [0], val_loss: 1.5442, val_acc: 0.7751\n",
            "Epoch [0], val_loss: 1.5436, val_acc: 0.7755\n",
            "Epoch [0], val_loss: 1.5431, val_acc: 0.7751\n",
            "Epoch [0], val_loss: 1.5426, val_acc: 0.7748\n",
            "Epoch [0], val_loss: 1.5421, val_acc: 0.7748\n",
            "Epoch [0], val_loss: 1.5416, val_acc: 0.7747\n",
            "Epoch [0], val_loss: 1.5411, val_acc: 0.7750\n",
            "Epoch [0], val_loss: 1.5406, val_acc: 0.7751\n",
            "Epoch [0], val_loss: 1.5401, val_acc: 0.7754\n",
            "Epoch [0], val_loss: 1.5396, val_acc: 0.7753\n",
            "Epoch [0], val_loss: 1.5391, val_acc: 0.7754\n",
            "Epoch [0], val_loss: 1.5386, val_acc: 0.7755\n",
            "Epoch [0], val_loss: 1.5380, val_acc: 0.7754\n",
            "Epoch [0], val_loss: 1.5375, val_acc: 0.7760\n",
            "Epoch [0], val_loss: 1.5370, val_acc: 0.7762\n",
            "Epoch [0], val_loss: 1.5365, val_acc: 0.7761\n",
            "Epoch [0], val_loss: 1.5361, val_acc: 0.7764\n",
            "Epoch [0], val_loss: 1.5356, val_acc: 0.7762\n",
            "Epoch [0], val_loss: 1.5350, val_acc: 0.7763\n",
            "Epoch [0], val_loss: 1.5345, val_acc: 0.7764\n",
            "Epoch [0], val_loss: 1.5340, val_acc: 0.7766\n",
            "Epoch [0], val_loss: 1.5335, val_acc: 0.7765\n",
            "Epoch [0], val_loss: 1.5330, val_acc: 0.7766\n",
            "Epoch [0], val_loss: 1.5325, val_acc: 0.7763\n",
            "Epoch [0], val_loss: 1.5320, val_acc: 0.7761\n",
            "Epoch [0], val_loss: 1.5315, val_acc: 0.7762\n",
            "Epoch [0], val_loss: 1.5310, val_acc: 0.7762\n",
            "Epoch [0], val_loss: 1.5305, val_acc: 0.7762\n",
            "Epoch [0], val_loss: 1.5300, val_acc: 0.7765\n",
            "Epoch [0], val_loss: 1.5295, val_acc: 0.7767\n",
            "Epoch [0], val_loss: 1.5290, val_acc: 0.7767\n",
            "Epoch [0], val_loss: 1.5285, val_acc: 0.7771\n",
            "Epoch [0], val_loss: 1.5280, val_acc: 0.7768\n",
            "Epoch [0], val_loss: 1.5275, val_acc: 0.7770\n",
            "Epoch [0], val_loss: 1.5270, val_acc: 0.7764\n",
            "Epoch [0], val_loss: 1.5265, val_acc: 0.7765\n",
            "Epoch [0], val_loss: 1.5260, val_acc: 0.7770\n",
            "Epoch [0], val_loss: 1.5255, val_acc: 0.7766\n",
            "Epoch [0], val_loss: 1.5250, val_acc: 0.7767\n",
            "Epoch [0], val_loss: 1.5245, val_acc: 0.7770\n",
            "Epoch [0], val_loss: 1.5241, val_acc: 0.7769\n",
            "Epoch [0], val_loss: 1.5236, val_acc: 0.7768\n",
            "Epoch [0], val_loss: 1.5231, val_acc: 0.7766\n",
            "Epoch [0], val_loss: 1.5226, val_acc: 0.7767\n",
            "Epoch [0], val_loss: 1.5221, val_acc: 0.7769\n",
            "Epoch [0], val_loss: 1.5216, val_acc: 0.7769\n",
            "Epoch [0], val_loss: 1.5212, val_acc: 0.7772\n",
            "Epoch [0], val_loss: 1.5207, val_acc: 0.7770\n",
            "Epoch [0], val_loss: 1.5202, val_acc: 0.7770\n",
            "Epoch [0], val_loss: 1.5197, val_acc: 0.7775\n",
            "Epoch [0], val_loss: 1.5192, val_acc: 0.7774\n",
            "Epoch [0], val_loss: 1.5187, val_acc: 0.7774\n",
            "Epoch [0], val_loss: 1.5182, val_acc: 0.7776\n",
            "Epoch [0], val_loss: 1.5177, val_acc: 0.7777\n",
            "Epoch [0], val_loss: 1.5172, val_acc: 0.7778\n",
            "Epoch [0], val_loss: 1.5168, val_acc: 0.7777\n",
            "Epoch [0], val_loss: 1.5163, val_acc: 0.7777\n",
            "Epoch [0], val_loss: 1.5158, val_acc: 0.7780\n",
            "Epoch [0], val_loss: 1.5153, val_acc: 0.7779\n",
            "Epoch [0], val_loss: 1.5148, val_acc: 0.7780\n",
            "Epoch [0], val_loss: 1.5144, val_acc: 0.7785\n",
            "Epoch [0], val_loss: 1.5138, val_acc: 0.7784\n",
            "Epoch [0], val_loss: 1.5133, val_acc: 0.7784\n",
            "Epoch [0], val_loss: 1.5129, val_acc: 0.7787\n",
            "Epoch [0], val_loss: 1.5124, val_acc: 0.7787\n",
            "Epoch [0], val_loss: 1.5119, val_acc: 0.7789\n",
            "Epoch [0], val_loss: 1.5114, val_acc: 0.7789\n",
            "Epoch [0], val_loss: 1.5109, val_acc: 0.7787\n",
            "Epoch [0], val_loss: 1.5104, val_acc: 0.7787\n",
            "Epoch [0], val_loss: 1.5100, val_acc: 0.7788\n",
            "Epoch [0], val_loss: 1.5095, val_acc: 0.7789\n",
            "Epoch [0], val_loss: 1.5091, val_acc: 0.7787\n",
            "Epoch [0], val_loss: 1.5086, val_acc: 0.7790\n",
            "Epoch [0], val_loss: 1.5081, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.5076, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.5071, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.5066, val_acc: 0.7789\n",
            "Epoch [0], val_loss: 1.5061, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.5056, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.5051, val_acc: 0.7790\n",
            "Epoch [0], val_loss: 1.5047, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.5043, val_acc: 0.7797\n",
            "Epoch [0], val_loss: 1.5038, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.5034, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.5029, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.5024, val_acc: 0.7800\n",
            "Epoch [0], val_loss: 1.5020, val_acc: 0.7801\n",
            "Epoch [0], val_loss: 1.5015, val_acc: 0.7801\n",
            "Epoch [0], val_loss: 1.5011, val_acc: 0.7800\n",
            "Epoch [0], val_loss: 1.5006, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.5001, val_acc: 0.7790\n",
            "Epoch [0], val_loss: 1.4996, val_acc: 0.7794\n",
            "Epoch [0], val_loss: 1.4991, val_acc: 0.7794\n",
            "Epoch [0], val_loss: 1.4987, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.4982, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.4978, val_acc: 0.7791\n",
            "Epoch [0], val_loss: 1.4973, val_acc: 0.7793\n",
            "Epoch [0], val_loss: 1.4968, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.4964, val_acc: 0.7793\n",
            "Epoch [0], val_loss: 1.4958, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.4954, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.4949, val_acc: 0.7792\n",
            "Epoch [0], val_loss: 1.4944, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.4940, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.4935, val_acc: 0.7795\n",
            "Epoch [0], val_loss: 1.4930, val_acc: 0.7794\n",
            "Epoch [0], val_loss: 1.4926, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.4921, val_acc: 0.7796\n",
            "Epoch [0], val_loss: 1.4916, val_acc: 0.7802\n",
            "Epoch [0], val_loss: 1.4911, val_acc: 0.7797\n",
            "Epoch [0], val_loss: 1.4907, val_acc: 0.7799\n",
            "Epoch [0], val_loss: 1.4902, val_acc: 0.7801\n",
            "Epoch [0], val_loss: 1.4898, val_acc: 0.7799\n",
            "Epoch [0], val_loss: 1.4893, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.4888, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.4884, val_acc: 0.7798\n",
            "Epoch [0], val_loss: 1.4879, val_acc: 0.7804\n",
            "Epoch [0], val_loss: 1.4874, val_acc: 0.7802\n",
            "Epoch [0], val_loss: 1.4870, val_acc: 0.7803\n",
            "Epoch [0], val_loss: 1.4865, val_acc: 0.7805\n",
            "Epoch [0], val_loss: 1.4861, val_acc: 0.7806\n",
            "Epoch [0], val_loss: 1.4856, val_acc: 0.7807\n",
            "Epoch [0], val_loss: 1.4852, val_acc: 0.7806\n",
            "Epoch [0], val_loss: 1.4847, val_acc: 0.7807\n",
            "Epoch [0], val_loss: 1.4842, val_acc: 0.7808\n",
            "Epoch [0], val_loss: 1.4838, val_acc: 0.7809\n",
            "Epoch [0], val_loss: 1.4833, val_acc: 0.7810\n",
            "Epoch [0], val_loss: 1.4829, val_acc: 0.7811\n",
            "Epoch [0], val_loss: 1.4824, val_acc: 0.7812\n",
            "Epoch [0], val_loss: 1.4820, val_acc: 0.7810\n",
            "Epoch [0], val_loss: 1.4815, val_acc: 0.7811\n",
            "Epoch [0], val_loss: 1.4810, val_acc: 0.7814\n",
            "Epoch [0], val_loss: 1.4806, val_acc: 0.7814\n",
            "Epoch [0], val_loss: 1.4802, val_acc: 0.7821\n",
            "Epoch [0], val_loss: 1.4797, val_acc: 0.7817\n",
            "Epoch [0], val_loss: 1.4792, val_acc: 0.7819\n",
            "Epoch [0], val_loss: 1.4787, val_acc: 0.7818\n",
            "Epoch [0], val_loss: 1.4783, val_acc: 0.7819\n",
            "Epoch [0], val_loss: 1.4778, val_acc: 0.7822\n",
            "Epoch [0], val_loss: 1.4773, val_acc: 0.7825\n",
            "Epoch [0], val_loss: 1.4769, val_acc: 0.7827\n",
            "Epoch [0], val_loss: 1.4765, val_acc: 0.7829\n",
            "Epoch [0], val_loss: 1.4760, val_acc: 0.7831\n",
            "Epoch [0], val_loss: 1.4755, val_acc: 0.7829\n",
            "Epoch [0], val_loss: 1.4751, val_acc: 0.7825\n",
            "Epoch [0], val_loss: 1.4746, val_acc: 0.7828\n",
            "Epoch [0], val_loss: 1.4742, val_acc: 0.7827\n",
            "Epoch [0], val_loss: 1.4737, val_acc: 0.7829\n",
            "Epoch [0], val_loss: 1.4733, val_acc: 0.7832\n",
            "Epoch [0], val_loss: 1.4729, val_acc: 0.7832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history4 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XTM4wAVvMBk",
        "outputId": "a8510500-e721-4aa1-d74a-3f11dd1be744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 1.4724, val_acc: 0.7829\n",
            "Epoch [0], val_loss: 1.4720, val_acc: 0.7832\n",
            "Epoch [0], val_loss: 1.4715, val_acc: 0.7835\n",
            "Epoch [0], val_loss: 1.4711, val_acc: 0.7835\n",
            "Epoch [0], val_loss: 1.4706, val_acc: 0.7839\n",
            "Epoch [0], val_loss: 1.4702, val_acc: 0.7840\n",
            "Epoch [0], val_loss: 1.4697, val_acc: 0.7836\n",
            "Epoch [0], val_loss: 1.4693, val_acc: 0.7832\n",
            "Epoch [0], val_loss: 1.4688, val_acc: 0.7835\n",
            "Epoch [0], val_loss: 1.4684, val_acc: 0.7835\n",
            "Epoch [0], val_loss: 1.4679, val_acc: 0.7836\n",
            "Epoch [0], val_loss: 1.4675, val_acc: 0.7837\n",
            "Epoch [0], val_loss: 1.4670, val_acc: 0.7833\n",
            "Epoch [0], val_loss: 1.4665, val_acc: 0.7832\n",
            "Epoch [0], val_loss: 1.4661, val_acc: 0.7838\n",
            "Epoch [0], val_loss: 1.4656, val_acc: 0.7836\n",
            "Epoch [0], val_loss: 1.4652, val_acc: 0.7839\n",
            "Epoch [0], val_loss: 1.4647, val_acc: 0.7837\n",
            "Epoch [0], val_loss: 1.4643, val_acc: 0.7835\n",
            "Epoch [0], val_loss: 1.4638, val_acc: 0.7838\n",
            "Epoch [0], val_loss: 1.4634, val_acc: 0.7839\n",
            "Epoch [0], val_loss: 1.4629, val_acc: 0.7834\n",
            "Epoch [0], val_loss: 1.4625, val_acc: 0.7834\n",
            "Epoch [0], val_loss: 1.4620, val_acc: 0.7842\n",
            "Epoch [0], val_loss: 1.4616, val_acc: 0.7845\n",
            "Epoch [0], val_loss: 1.4612, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4608, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4603, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4599, val_acc: 0.7846\n",
            "Epoch [0], val_loss: 1.4595, val_acc: 0.7846\n",
            "Epoch [0], val_loss: 1.4590, val_acc: 0.7846\n",
            "Epoch [0], val_loss: 1.4586, val_acc: 0.7848\n",
            "Epoch [0], val_loss: 1.4582, val_acc: 0.7849\n",
            "Epoch [0], val_loss: 1.4577, val_acc: 0.7844\n",
            "Epoch [0], val_loss: 1.4573, val_acc: 0.7844\n",
            "Epoch [0], val_loss: 1.4569, val_acc: 0.7843\n",
            "Epoch [0], val_loss: 1.4564, val_acc: 0.7842\n",
            "Epoch [0], val_loss: 1.4560, val_acc: 0.7846\n",
            "Epoch [0], val_loss: 1.4556, val_acc: 0.7845\n",
            "Epoch [0], val_loss: 1.4552, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4547, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4543, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4539, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4535, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4530, val_acc: 0.7851\n",
            "Epoch [0], val_loss: 1.4526, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4521, val_acc: 0.7848\n",
            "Epoch [0], val_loss: 1.4517, val_acc: 0.7847\n",
            "Epoch [0], val_loss: 1.4513, val_acc: 0.7848\n",
            "Epoch [0], val_loss: 1.4508, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4504, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4499, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4495, val_acc: 0.7849\n",
            "Epoch [0], val_loss: 1.4490, val_acc: 0.7850\n",
            "Epoch [0], val_loss: 1.4486, val_acc: 0.7853\n",
            "Epoch [0], val_loss: 1.4482, val_acc: 0.7851\n",
            "Epoch [0], val_loss: 1.4477, val_acc: 0.7859\n",
            "Epoch [0], val_loss: 1.4473, val_acc: 0.7855\n",
            "Epoch [0], val_loss: 1.4468, val_acc: 0.7857\n",
            "Epoch [0], val_loss: 1.4464, val_acc: 0.7852\n",
            "Epoch [0], val_loss: 1.4460, val_acc: 0.7852\n",
            "Epoch [0], val_loss: 1.4455, val_acc: 0.7854\n",
            "Epoch [0], val_loss: 1.4451, val_acc: 0.7853\n",
            "Epoch [0], val_loss: 1.4446, val_acc: 0.7854\n",
            "Epoch [0], val_loss: 1.4442, val_acc: 0.7854\n",
            "Epoch [0], val_loss: 1.4438, val_acc: 0.7856\n",
            "Epoch [0], val_loss: 1.4433, val_acc: 0.7854\n",
            "Epoch [0], val_loss: 1.4430, val_acc: 0.7856\n",
            "Epoch [0], val_loss: 1.4425, val_acc: 0.7859\n",
            "Epoch [0], val_loss: 1.4421, val_acc: 0.7855\n",
            "Epoch [0], val_loss: 1.4417, val_acc: 0.7864\n",
            "Epoch [0], val_loss: 1.4412, val_acc: 0.7855\n",
            "Epoch [0], val_loss: 1.4408, val_acc: 0.7863\n",
            "Epoch [0], val_loss: 1.4404, val_acc: 0.7866\n",
            "Epoch [0], val_loss: 1.4399, val_acc: 0.7858\n",
            "Epoch [0], val_loss: 1.4395, val_acc: 0.7865\n",
            "Epoch [0], val_loss: 1.4391, val_acc: 0.7869\n",
            "Epoch [0], val_loss: 1.4386, val_acc: 0.7864\n",
            "Epoch [0], val_loss: 1.4382, val_acc: 0.7864\n",
            "Epoch [0], val_loss: 1.4377, val_acc: 0.7870\n",
            "Epoch [0], val_loss: 1.4373, val_acc: 0.7867\n",
            "Epoch [0], val_loss: 1.4369, val_acc: 0.7865\n",
            "Epoch [0], val_loss: 1.4364, val_acc: 0.7872\n",
            "Epoch [0], val_loss: 1.4360, val_acc: 0.7868\n",
            "Epoch [0], val_loss: 1.4356, val_acc: 0.7874\n",
            "Epoch [0], val_loss: 1.4351, val_acc: 0.7873\n",
            "Epoch [0], val_loss: 1.4347, val_acc: 0.7868\n",
            "Epoch [0], val_loss: 1.4343, val_acc: 0.7870\n",
            "Epoch [0], val_loss: 1.4338, val_acc: 0.7872\n",
            "Epoch [0], val_loss: 1.4334, val_acc: 0.7866\n",
            "Epoch [0], val_loss: 1.4330, val_acc: 0.7865\n",
            "Epoch [0], val_loss: 1.4326, val_acc: 0.7865\n",
            "Epoch [0], val_loss: 1.4322, val_acc: 0.7868\n",
            "Epoch [0], val_loss: 1.4318, val_acc: 0.7867\n",
            "Epoch [0], val_loss: 1.4313, val_acc: 0.7873\n",
            "Epoch [0], val_loss: 1.4309, val_acc: 0.7876\n",
            "Epoch [0], val_loss: 1.4305, val_acc: 0.7872\n",
            "Epoch [0], val_loss: 1.4301, val_acc: 0.7874\n",
            "Epoch [0], val_loss: 1.4296, val_acc: 0.7874\n",
            "Epoch [0], val_loss: 1.4292, val_acc: 0.7875\n",
            "Epoch [0], val_loss: 1.4288, val_acc: 0.7875\n",
            "Epoch [0], val_loss: 1.4283, val_acc: 0.7872\n",
            "Epoch [0], val_loss: 1.4279, val_acc: 0.7874\n",
            "Epoch [0], val_loss: 1.4275, val_acc: 0.7876\n",
            "Epoch [0], val_loss: 1.4271, val_acc: 0.7874\n",
            "Epoch [0], val_loss: 1.4267, val_acc: 0.7879\n",
            "Epoch [0], val_loss: 1.4263, val_acc: 0.7877\n",
            "Epoch [0], val_loss: 1.4259, val_acc: 0.7878\n",
            "Epoch [0], val_loss: 1.4255, val_acc: 0.7877\n",
            "Epoch [0], val_loss: 1.4251, val_acc: 0.7877\n",
            "Epoch [0], val_loss: 1.4247, val_acc: 0.7875\n",
            "Epoch [0], val_loss: 1.4242, val_acc: 0.7876\n",
            "Epoch [0], val_loss: 1.4238, val_acc: 0.7875\n",
            "Epoch [0], val_loss: 1.4235, val_acc: 0.7875\n",
            "Epoch [0], val_loss: 1.4230, val_acc: 0.7877\n",
            "Epoch [0], val_loss: 1.4226, val_acc: 0.7881\n",
            "Epoch [0], val_loss: 1.4221, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4217, val_acc: 0.7887\n",
            "Epoch [0], val_loss: 1.4213, val_acc: 0.7884\n",
            "Epoch [0], val_loss: 1.4208, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4204, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4199, val_acc: 0.7879\n",
            "Epoch [0], val_loss: 1.4195, val_acc: 0.7881\n",
            "Epoch [0], val_loss: 1.4191, val_acc: 0.7880\n",
            "Epoch [0], val_loss: 1.4187, val_acc: 0.7880\n",
            "Epoch [0], val_loss: 1.4182, val_acc: 0.7879\n",
            "Epoch [0], val_loss: 1.4178, val_acc: 0.7880\n",
            "Epoch [0], val_loss: 1.4174, val_acc: 0.7881\n",
            "Epoch [0], val_loss: 1.4170, val_acc: 0.7884\n",
            "Epoch [0], val_loss: 1.4165, val_acc: 0.7886\n",
            "Epoch [0], val_loss: 1.4161, val_acc: 0.7886\n",
            "Epoch [0], val_loss: 1.4157, val_acc: 0.7885\n",
            "Epoch [0], val_loss: 1.4153, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4149, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4145, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4141, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4136, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4132, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4128, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4124, val_acc: 0.7879\n",
            "Epoch [0], val_loss: 1.4120, val_acc: 0.7882\n",
            "Epoch [0], val_loss: 1.4116, val_acc: 0.7883\n",
            "Epoch [0], val_loss: 1.4111, val_acc: 0.7884\n",
            "Epoch [0], val_loss: 1.4107, val_acc: 0.7885\n",
            "Epoch [0], val_loss: 1.4103, val_acc: 0.7887\n",
            "Epoch [0], val_loss: 1.4099, val_acc: 0.7887\n",
            "Epoch [0], val_loss: 1.4095, val_acc: 0.7887\n",
            "Epoch [0], val_loss: 1.4091, val_acc: 0.7888\n",
            "Epoch [0], val_loss: 1.4087, val_acc: 0.7888\n",
            "Epoch [0], val_loss: 1.4083, val_acc: 0.7888\n",
            "Epoch [0], val_loss: 1.4079, val_acc: 0.7890\n",
            "Epoch [0], val_loss: 1.4075, val_acc: 0.7893\n",
            "Epoch [0], val_loss: 1.4071, val_acc: 0.7894\n",
            "Epoch [0], val_loss: 1.4067, val_acc: 0.7894\n",
            "Epoch [0], val_loss: 1.4063, val_acc: 0.7895\n",
            "Epoch [0], val_loss: 1.4059, val_acc: 0.7898\n",
            "Epoch [0], val_loss: 1.4055, val_acc: 0.7897\n",
            "Epoch [0], val_loss: 1.4051, val_acc: 0.7895\n",
            "Epoch [0], val_loss: 1.4047, val_acc: 0.7895\n",
            "Epoch [0], val_loss: 1.4043, val_acc: 0.7896\n",
            "Epoch [0], val_loss: 1.4039, val_acc: 0.7900\n",
            "Epoch [0], val_loss: 1.4035, val_acc: 0.7897\n",
            "Epoch [0], val_loss: 1.4031, val_acc: 0.7899\n",
            "Epoch [0], val_loss: 1.4027, val_acc: 0.7900\n",
            "Epoch [0], val_loss: 1.4023, val_acc: 0.7900\n",
            "Epoch [0], val_loss: 1.4019, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.4015, val_acc: 0.7903\n",
            "Epoch [0], val_loss: 1.4011, val_acc: 0.7904\n",
            "Epoch [0], val_loss: 1.4007, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.4004, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.4000, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.3996, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.3992, val_acc: 0.7903\n",
            "Epoch [0], val_loss: 1.3987, val_acc: 0.7906\n",
            "Epoch [0], val_loss: 1.3983, val_acc: 0.7907\n",
            "Epoch [0], val_loss: 1.3979, val_acc: 0.7907\n",
            "Epoch [0], val_loss: 1.3976, val_acc: 0.7908\n",
            "Epoch [0], val_loss: 1.3971, val_acc: 0.7906\n",
            "Epoch [0], val_loss: 1.3967, val_acc: 0.7908\n",
            "Epoch [0], val_loss: 1.3963, val_acc: 0.7906\n",
            "Epoch [0], val_loss: 1.3959, val_acc: 0.7905\n",
            "Epoch [0], val_loss: 1.3955, val_acc: 0.7902\n",
            "Epoch [0], val_loss: 1.3951, val_acc: 0.7904\n",
            "Epoch [0], val_loss: 1.3947, val_acc: 0.7906\n",
            "Epoch [0], val_loss: 1.3944, val_acc: 0.7905\n",
            "Epoch [0], val_loss: 1.3939, val_acc: 0.7909\n",
            "Epoch [0], val_loss: 1.3936, val_acc: 0.7909\n",
            "Epoch [0], val_loss: 1.3932, val_acc: 0.7909\n",
            "Epoch [0], val_loss: 1.3928, val_acc: 0.7908\n",
            "Epoch [0], val_loss: 1.3924, val_acc: 0.7907\n",
            "Epoch [0], val_loss: 1.3920, val_acc: 0.7909\n",
            "Epoch [0], val_loss: 1.3916, val_acc: 0.7912\n",
            "Epoch [0], val_loss: 1.3912, val_acc: 0.7913\n",
            "Epoch [0], val_loss: 1.3908, val_acc: 0.7913\n",
            "Epoch [0], val_loss: 1.3904, val_acc: 0.7910\n",
            "Epoch [0], val_loss: 1.3900, val_acc: 0.7911\n",
            "Epoch [0], val_loss: 1.3896, val_acc: 0.7914\n",
            "Epoch [0], val_loss: 1.3892, val_acc: 0.7915\n",
            "Epoch [0], val_loss: 1.3888, val_acc: 0.7917\n",
            "Epoch [0], val_loss: 1.3884, val_acc: 0.7918\n",
            "Epoch [0], val_loss: 1.3880, val_acc: 0.7915\n",
            "Epoch [0], val_loss: 1.3877, val_acc: 0.7919\n",
            "Epoch [0], val_loss: 1.3873, val_acc: 0.7918\n",
            "Epoch [0], val_loss: 1.3869, val_acc: 0.7917\n",
            "Epoch [0], val_loss: 1.3865, val_acc: 0.7916\n",
            "Epoch [0], val_loss: 1.3861, val_acc: 0.7917\n",
            "Epoch [0], val_loss: 1.3857, val_acc: 0.7920\n",
            "Epoch [0], val_loss: 1.3853, val_acc: 0.7923\n",
            "Epoch [0], val_loss: 1.3849, val_acc: 0.7923\n",
            "Epoch [0], val_loss: 1.3845, val_acc: 0.7923\n",
            "Epoch [0], val_loss: 1.3842, val_acc: 0.7922\n",
            "Epoch [0], val_loss: 1.3838, val_acc: 0.7924\n",
            "Epoch [0], val_loss: 1.3834, val_acc: 0.7923\n",
            "Epoch [0], val_loss: 1.3830, val_acc: 0.7923\n",
            "Epoch [0], val_loss: 1.3826, val_acc: 0.7924\n",
            "Epoch [0], val_loss: 1.3822, val_acc: 0.7925\n",
            "Epoch [0], val_loss: 1.3818, val_acc: 0.7926\n",
            "Epoch [0], val_loss: 1.3814, val_acc: 0.7926\n",
            "Epoch [0], val_loss: 1.3810, val_acc: 0.7925\n",
            "Epoch [0], val_loss: 1.3806, val_acc: 0.7929\n",
            "Epoch [0], val_loss: 1.3803, val_acc: 0.7931\n",
            "Epoch [0], val_loss: 1.3799, val_acc: 0.7933\n",
            "Epoch [0], val_loss: 1.3795, val_acc: 0.7932\n",
            "Epoch [0], val_loss: 1.3791, val_acc: 0.7927\n",
            "Epoch [0], val_loss: 1.3787, val_acc: 0.7925\n",
            "Epoch [0], val_loss: 1.3783, val_acc: 0.7927\n",
            "Epoch [0], val_loss: 1.3779, val_acc: 0.7925\n",
            "Epoch [0], val_loss: 1.3775, val_acc: 0.7927\n",
            "Epoch [0], val_loss: 1.3771, val_acc: 0.7928\n",
            "Epoch [0], val_loss: 1.3767, val_acc: 0.7928\n",
            "Epoch [0], val_loss: 1.3764, val_acc: 0.7930\n",
            "Epoch [0], val_loss: 1.3760, val_acc: 0.7929\n",
            "Epoch [0], val_loss: 1.3756, val_acc: 0.7934\n",
            "Epoch [0], val_loss: 1.3752, val_acc: 0.7929\n",
            "Epoch [0], val_loss: 1.3749, val_acc: 0.7934\n",
            "Epoch [0], val_loss: 1.3745, val_acc: 0.7932\n",
            "Epoch [0], val_loss: 1.3741, val_acc: 0.7931\n",
            "Epoch [0], val_loss: 1.3737, val_acc: 0.7935\n",
            "Epoch [0], val_loss: 1.3733, val_acc: 0.7935\n",
            "Epoch [0], val_loss: 1.3729, val_acc: 0.7933\n",
            "Epoch [0], val_loss: 1.3725, val_acc: 0.7934\n",
            "Epoch [0], val_loss: 1.3722, val_acc: 0.7939\n",
            "Epoch [0], val_loss: 1.3718, val_acc: 0.7935\n",
            "Epoch [0], val_loss: 1.3714, val_acc: 0.7933\n",
            "Epoch [0], val_loss: 1.3710, val_acc: 0.7933\n",
            "Epoch [0], val_loss: 1.3706, val_acc: 0.7935\n",
            "Epoch [0], val_loss: 1.3702, val_acc: 0.7932\n",
            "Epoch [0], val_loss: 1.3699, val_acc: 0.7932\n",
            "Epoch [0], val_loss: 1.3695, val_acc: 0.7934\n",
            "Epoch [0], val_loss: 1.3691, val_acc: 0.7936\n",
            "Epoch [0], val_loss: 1.3687, val_acc: 0.7940\n",
            "Epoch [0], val_loss: 1.3683, val_acc: 0.7941\n",
            "Epoch [0], val_loss: 1.3679, val_acc: 0.7943\n",
            "Epoch [0], val_loss: 1.3675, val_acc: 0.7947\n",
            "Epoch [0], val_loss: 1.3672, val_acc: 0.7945\n",
            "Epoch [0], val_loss: 1.3668, val_acc: 0.7946\n",
            "Epoch [0], val_loss: 1.3664, val_acc: 0.7947\n",
            "Epoch [0], val_loss: 1.3661, val_acc: 0.7952\n",
            "Epoch [0], val_loss: 1.3657, val_acc: 0.7950\n",
            "Epoch [0], val_loss: 1.3652, val_acc: 0.7953\n",
            "Epoch [0], val_loss: 1.3649, val_acc: 0.7953\n",
            "Epoch [0], val_loss: 1.3645, val_acc: 0.7955\n",
            "Epoch [0], val_loss: 1.3641, val_acc: 0.7957\n",
            "Epoch [0], val_loss: 1.3637, val_acc: 0.7958\n",
            "Epoch [0], val_loss: 1.3634, val_acc: 0.7957\n",
            "Epoch [0], val_loss: 1.3630, val_acc: 0.7959\n",
            "Epoch [0], val_loss: 1.3626, val_acc: 0.7961\n",
            "Epoch [0], val_loss: 1.3623, val_acc: 0.7966\n",
            "Epoch [0], val_loss: 1.3619, val_acc: 0.7959\n",
            "Epoch [0], val_loss: 1.3615, val_acc: 0.7962\n",
            "Epoch [0], val_loss: 1.3612, val_acc: 0.7965\n",
            "Epoch [0], val_loss: 1.3608, val_acc: 0.7966\n",
            "Epoch [0], val_loss: 1.3604, val_acc: 0.7967\n",
            "Epoch [0], val_loss: 1.3600, val_acc: 0.7965\n",
            "Epoch [0], val_loss: 1.3597, val_acc: 0.7966\n",
            "Epoch [0], val_loss: 1.3593, val_acc: 0.7968\n",
            "Epoch [0], val_loss: 1.3589, val_acc: 0.7971\n",
            "Epoch [0], val_loss: 1.3586, val_acc: 0.7971\n",
            "Epoch [0], val_loss: 1.3582, val_acc: 0.7973\n",
            "Epoch [0], val_loss: 1.3578, val_acc: 0.7973\n",
            "Epoch [0], val_loss: 1.3575, val_acc: 0.7976\n",
            "Epoch [0], val_loss: 1.3571, val_acc: 0.7973\n",
            "Epoch [0], val_loss: 1.3567, val_acc: 0.7973\n",
            "Epoch [0], val_loss: 1.3563, val_acc: 0.7974\n",
            "Epoch [0], val_loss: 1.3560, val_acc: 0.7975\n",
            "Epoch [0], val_loss: 1.3556, val_acc: 0.7974\n",
            "Epoch [0], val_loss: 1.3552, val_acc: 0.7977\n",
            "Epoch [0], val_loss: 1.3548, val_acc: 0.7977\n",
            "Epoch [0], val_loss: 1.3545, val_acc: 0.7976\n",
            "Epoch [0], val_loss: 1.3541, val_acc: 0.7976\n",
            "Epoch [0], val_loss: 1.3538, val_acc: 0.7977\n",
            "Epoch [0], val_loss: 1.3533, val_acc: 0.7979\n",
            "Epoch [0], val_loss: 1.3529, val_acc: 0.7978\n",
            "Epoch [0], val_loss: 1.3526, val_acc: 0.7978\n",
            "Epoch [0], val_loss: 1.3522, val_acc: 0.7980\n",
            "Epoch [0], val_loss: 1.3518, val_acc: 0.7978\n",
            "Epoch [0], val_loss: 1.3515, val_acc: 0.7983\n",
            "Epoch [0], val_loss: 1.3511, val_acc: 0.7982\n",
            "Epoch [0], val_loss: 1.3507, val_acc: 0.7982\n",
            "Epoch [0], val_loss: 1.3503, val_acc: 0.7984\n",
            "Epoch [0], val_loss: 1.3500, val_acc: 0.7982\n",
            "Epoch [0], val_loss: 1.3496, val_acc: 0.7986\n",
            "Epoch [0], val_loss: 1.3492, val_acc: 0.7986\n",
            "Epoch [0], val_loss: 1.3488, val_acc: 0.7988\n",
            "Epoch [0], val_loss: 1.3485, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3481, val_acc: 0.7989\n",
            "Epoch [0], val_loss: 1.3478, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3474, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3470, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3466, val_acc: 0.7992\n",
            "Epoch [0], val_loss: 1.3463, val_acc: 0.7992\n",
            "Epoch [0], val_loss: 1.3459, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3455, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3452, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3448, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3445, val_acc: 0.7990\n",
            "Epoch [0], val_loss: 1.3441, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3437, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3434, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3430, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3426, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3423, val_acc: 0.7993\n",
            "Epoch [0], val_loss: 1.3419, val_acc: 0.7996\n",
            "Epoch [0], val_loss: 1.3416, val_acc: 0.7993\n",
            "Epoch [0], val_loss: 1.3412, val_acc: 0.7995\n",
            "Epoch [0], val_loss: 1.3408, val_acc: 0.7993\n",
            "Epoch [0], val_loss: 1.3404, val_acc: 0.7994\n",
            "Epoch [0], val_loss: 1.3401, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3397, val_acc: 0.7992\n",
            "Epoch [0], val_loss: 1.3393, val_acc: 0.7991\n",
            "Epoch [0], val_loss: 1.3390, val_acc: 0.7994\n",
            "Epoch [0], val_loss: 1.3386, val_acc: 0.7994\n",
            "Epoch [0], val_loss: 1.3383, val_acc: 0.7996\n",
            "Epoch [0], val_loss: 1.3379, val_acc: 0.8000\n",
            "Epoch [0], val_loss: 1.3376, val_acc: 0.7999\n",
            "Epoch [0], val_loss: 1.3372, val_acc: 0.8001\n",
            "Epoch [0], val_loss: 1.3368, val_acc: 0.7998\n",
            "Epoch [0], val_loss: 1.3365, val_acc: 0.7997\n",
            "Epoch [0], val_loss: 1.3362, val_acc: 0.7998\n",
            "Epoch [0], val_loss: 1.3358, val_acc: 0.7996\n",
            "Epoch [0], val_loss: 1.3354, val_acc: 0.7996\n",
            "Epoch [0], val_loss: 1.3351, val_acc: 0.7995\n",
            "Epoch [0], val_loss: 1.3347, val_acc: 0.7996\n",
            "Epoch [0], val_loss: 1.3344, val_acc: 0.7999\n",
            "Epoch [0], val_loss: 1.3340, val_acc: 0.7998\n",
            "Epoch [0], val_loss: 1.3336, val_acc: 0.7999\n",
            "Epoch [0], val_loss: 1.3333, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3329, val_acc: 0.8004\n",
            "Epoch [0], val_loss: 1.3326, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3322, val_acc: 0.8004\n",
            "Epoch [0], val_loss: 1.3318, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3315, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3311, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3308, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3304, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3301, val_acc: 0.8005\n",
            "Epoch [0], val_loss: 1.3297, val_acc: 0.8006\n",
            "Epoch [0], val_loss: 1.3294, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3290, val_acc: 0.8005\n",
            "Epoch [0], val_loss: 1.3287, val_acc: 0.8008\n",
            "Epoch [0], val_loss: 1.3283, val_acc: 0.8007\n",
            "Epoch [0], val_loss: 1.3280, val_acc: 0.8006\n",
            "Epoch [0], val_loss: 1.3276, val_acc: 0.8006\n",
            "Epoch [0], val_loss: 1.3273, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3269, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3265, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3262, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3258, val_acc: 0.8002\n",
            "Epoch [0], val_loss: 1.3254, val_acc: 0.8009\n",
            "Epoch [0], val_loss: 1.3250, val_acc: 0.8014\n",
            "Epoch [0], val_loss: 1.3247, val_acc: 0.8015\n",
            "Epoch [0], val_loss: 1.3243, val_acc: 0.8014\n",
            "Epoch [0], val_loss: 1.3240, val_acc: 0.8015\n",
            "Epoch [0], val_loss: 1.3236, val_acc: 0.8017\n",
            "Epoch [0], val_loss: 1.3232, val_acc: 0.8014\n",
            "Epoch [0], val_loss: 1.3229, val_acc: 0.8015\n",
            "Epoch [0], val_loss: 1.3225, val_acc: 0.8015\n",
            "Epoch [0], val_loss: 1.3222, val_acc: 0.8014\n",
            "Epoch [0], val_loss: 1.3218, val_acc: 0.8008\n",
            "Epoch [0], val_loss: 1.3215, val_acc: 0.8009\n",
            "Epoch [0], val_loss: 1.3211, val_acc: 0.8007\n",
            "Epoch [0], val_loss: 1.3208, val_acc: 0.8008\n",
            "Epoch [0], val_loss: 1.3205, val_acc: 0.8010\n",
            "Epoch [0], val_loss: 1.3201, val_acc: 0.8017\n",
            "Epoch [0], val_loss: 1.3198, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3194, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3191, val_acc: 0.8006\n",
            "Epoch [0], val_loss: 1.3188, val_acc: 0.8005\n",
            "Epoch [0], val_loss: 1.3184, val_acc: 0.8003\n",
            "Epoch [0], val_loss: 1.3181, val_acc: 0.8004\n",
            "Epoch [0], val_loss: 1.3178, val_acc: 0.8003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We have the accuracy of 80%"
      ],
      "metadata": {
        "id": "YETOkm4Y4KDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets plot this"
      ],
      "metadata": {
        "id": "pKPjm9pQ4_yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = [result0] + history1 + history2 + history3 + history4\n",
        "accuracies = [result['val_acc'] for result in history]\n",
        "plt.plot(accuracies, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vWetgGXvvOuw",
        "outputId": "1027f243-798a-4899-dd44-309804da7121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WroPTo4T5Dge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}